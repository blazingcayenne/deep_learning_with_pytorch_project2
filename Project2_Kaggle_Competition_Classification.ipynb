{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhTA9Jbl3-5s"
   },
   "source": [
    "# <font style=\"color:blue\">Project 2: Kaggle Competition - Classification</font>\n",
    "\n",
    "#### Maximum Points: 100\n",
    "\n",
    "<div>\n",
    "    <table>\n",
    "        <tr><td><h3>Sr. no.</h3></td> <td><h3>Section</h3></td> <td><h3>Points</h3></td> </tr>\n",
    "        <tr><td><h3>1</h3></td> <td><h3>Data Loader</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>2</h3></td> <td><h3>Configuration</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>3</h3></td> <td><h3>Evaluation Metric</h3></td> <td><h3>10</h3></td> </tr>\n",
    "        <tr><td><h3>4</h3></td> <td><h3>Train and Validation</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>5</h3></td> <td><h3>Model</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>6</h3></td> <td><h3>Utils</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>7</h3></td> <td><h3>Experiment</h3></td><td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>8</h3></td> <td><h3>TensorBoard Dev Scalars Log Link</h3></td> <td><h3>5</h3></td> </tr>\n",
    "        <tr><td><h3>9</h3></td> <td><h3>Kaggle Profile Link</h3></td> <td><h3>50</h3></td> </tr>\n",
    "    </table>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:green\">Project Approach</font>\n",
    "\n",
    "The <a href=\"https://www.analyticsvidhya.com/blog/2017/06/transfer-learning-the-art-of-fine-tuning-a-pre-trained-model/\"><b>Transfer learning and the art of using Pre-trained Models in Deep Learning</b></a> blog post outlines four ways to fine tune a model that has been trained on a different dataset. The following is a short section of this post that I slightly changed.\n",
    "\n",
    "The following diagram helps one decide how to use a pretrained model on a new data set.\n",
    "\n",
    "<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2017/05/31112715/finetune1.jpg\" />\n",
    "\n",
    "<b>Scenario 1: Size of the data set is small and the data similarity is high.</b> In this case, since the data similarity is very high, we do not need to retrain the model. All we need to do is to customize and modify the output layers according to our problem statement. We use the pretrained model as a feature extractor and retrain the classification block/layer.\n",
    "\n",
    "<b>Scenario 2: Size of the data set is small and the data similairity is low.</b> In this case we can freeze the initial (letâ€™s say k) layers of the pretrained model and train just the remaining(n-k) layers again. The top layers would then be customized to the new data set. Since the new data set has low similarity it is significant to retrain and customize the higher layers according to the new dataset.  The small size of the data set is compensated by the fact that the initial layers are kept pretrained(which have been trained on a large dataset previously) and the weights for those layers are frozen.\n",
    "\n",
    "<b>Scenario 3: Size of the data set is large and the data similarity is low.</b>  In this case, since we have a large dataset, our neural network training would be effective. However, since the data we have is very different as compared to the data used for training our pretrained models. The predictions made using pretrained models would not be effective. Hence, its best to train the neural network from scratch according to your data.\n",
    "\n",
    "<b>Scenario 4: Size of the data set is large and the data similarity is high.</b> This is the ideal situation. In this case the pretrained model should be most effective. The best way to use the model is to retain the architecture of the model and the initial weights of the model. Then we can retrain this model using the weights as initialized in the pre-trained model.\n",
    "\n",
    "<hr>\n",
    "\n",
    "Since I did not know how to program in Python before this class, I am using this project to improve my Python proficiency. Consequently, I will not only to explore using pretrained models on a new data set, but I will also spend significant time developing class hierachies that will allow me to easily conduct experiments on the following pretrained TorchVision models using any of the scenarios described above.\n",
    "<ul>\n",
    "    <li>ResNet-18</li>\n",
    "    <li>ResNet-34</li>\n",
    "    <li>ResNet-50</li>\n",
    "    <li>ResNet-101</li>\n",
    "    <li>ResNet-152</li>\n",
    "    <li>VGG-11 with batch normalization</li>\n",
    "    <li>VGG-13 with batch normalization</li>\n",
    "    <li>VGG-16 with batch normalization</li>\n",
    "    <li>VGG-19 with batch normalization</li>\n",
    "    <li>DenseNet-121</li>\n",
    "    <li>DenseNet-169</li>\n",
    "    <li>DenseNet-201</li>\n",
    "    <li>DenseNet-161</li>\n",
    "    <li>ResNeXt-50-32x4d</li>\n",
    "    <li>ResNeXt-101-32x8d</li>\n",
    "    <li>Wide ResNet-50-2</li>\n",
    "    <li>Wide ResNet-101-2</li>\n",
    "</ul>\n",
    "\n",
    "Because I want to improve my Python proficiency, I decided to use and modify the trainer module rather than use Pytorch Lightning. Modications to the trainer module include, but are not limited to, adding additinal configuration parameters, adding the ability to prematurely stop training when either the loss or accuracy does not significantly improve over a certain number of epochs, extending the visualization base and TensorBoard classes to allow logging of images, figures, graphs, and PR curves.\n",
    "\n",
    "Experiments will be identified with the prefix \"Exp\" followed by two numbers and a letter (regular expression = Exp\\[0-9\\]\\[0-9\\]\\[A-Z\\]). The first and second numbers will designate the experiment group and set respectiviely, while the letter will designates an individual experiment. Hence, all experiments that begin with \"Exp0\" belong the Group 0, while all experiments that begin with \"Exp01\" belong to Group 0, Set 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4LNCmWgkBNLg",
    "outputId": "0f7e955d-30be-430c-ffc5-a64ec8d98ae4"
   },
   "outputs": [],
   "source": [
    "# This cell initializes the notebook for execution on different hosts.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "def get_host() -> str:\n",
    "    \"\"\"\n",
    "    The get_ipython() function returns the following from different hosts.\n",
    "\n",
    "    colab:  <google.colab._shell.Shell object at 0x7f23c5e386d8>\n",
    "    brule:  <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f1990f22a50>\n",
    "    kaggle: <ipykernel.zmqshell.ZMQInteractiveShell object at 0x7f9d093aebd0>\n",
    "    \"\"\"\n",
    "    \n",
    "    if 'google.colab' in str(get_ipython()):\n",
    "        return \"colab\"\n",
    "    else:\n",
    "        # ToDo: Determine whether running on kaggle.\n",
    "        return \"brule\"\n",
    "\n",
    "def init_host(host:str):\n",
    "    if host == \"brule\":\n",
    "        # set data and project directories\n",
    "        if os.path.isdir(\"./trainer\"):\n",
    "            data_dir = \"./data\"\n",
    "            proj_dir = \"./\"\n",
    "        elif os.path.isdir(\"./project2/trainer\"):\n",
    "            data_dir = \"./project2/data\"\n",
    "            proj_dir = \"./project2\"\n",
    "        else:\n",
    "            raise SystemExit(\"Cannot locate trainer module.\")\n",
    "\n",
    "    elif host == \"colab\":\n",
    "        # mount Google Drive\n",
    "        from google.colab import drive\n",
    "        drive.mount(\"/content/gdrive\")\n",
    "\n",
    "        # set data and project directories\n",
    "        data_dir = \"/content/data\"\n",
    "        proj_dir = \"/content/gdrive/MyDrive/Colab Notebooks/project2\"\n",
    "\n",
    "        # fetching data from Google Drive is very, very slow ...\n",
    "        # hence, we will unzip the dataset to /content/data if it is not there\n",
    "        dataset = os.path.join(proj_dir, \"data\", \"pytorch-opencv-course-classification.zip\")\n",
    "        if not os.path.isdir(data_dir):\n",
    "              os.makedirs(data_dir)\n",
    "              import zipfile\n",
    "              with zipfile.ZipFile(dataset, 'r') as zip_ref:\n",
    "                  zip_ref.extractall(data_dir)              \n",
    "\n",
    "    else:\n",
    "        raise SystemExit(\"Unknown host! Cannot continue.\")\n",
    "\n",
    "    sys.path.append(proj_dir)\n",
    "    return data_dir, proj_dir\n",
    "\n",
    "data_dir, proj_dir = init_host(get_host())\n",
    "\n",
    "print(f\"data_dir: {data_dir}\")\n",
    "!ls -lh {data_dir.replace(\" \", \"\\\\ \")}\n",
    "\n",
    "print(f\"proj_dir: {proj_dir}\")\n",
    "!ls -lh {proj_dir.replace(\" \", \"\\\\ \")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xiq8YhMC3-5w"
   },
   "outputs": [],
   "source": [
    "# import organzier @ https://pypi.org/project/importanize/\n",
    "\n",
    "from abc import ABC, abstractmethod, abstractproperty\n",
    "from collections import namedtuple\n",
    "from dataclasses import dataclass, replace\n",
    "from enum import Enum, auto\n",
    "from operator import itemgetter\n",
    "from typing import Callable, Iterable, List, Tuple\n",
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from trainer import Trainer, configuration, hooks\n",
    "from trainer.configuration import SystemConfig\n",
    "from trainer.configuration import DataAugConfig, DatasetConfig, DataLoaderConfig\n",
    "from trainer.configuration import OptimizerConfig, SchedulerConfig, TrainerConfig\n",
    "from trainer.metrics import AccuracyEstimator\n",
    "from trainer.tensorboard_visualizer import TensorBoardVisualizer\n",
    "from trainer.utils import patch_configs, setup_system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VWi_M1eB3-5x"
   },
   "source": [
    "## <font style=\"color:green\">1. Data Loader [10 Points]</font>\n",
    "\n",
    "In this section, you have to write a class or methods that will be used to get training and validation data\n",
    "loader.\n",
    "\n",
    "You will have to write a custom dataset class to load data.\n",
    "\n",
    "**Note that there are not separate validation data, so you will have to create your validation set by dividing train data into train and validation data. Usually, in practice, we do `80:20` ratio for train and validation, respectively.** \n",
    "\n",
    "For example,\n",
    "\n",
    "```\n",
    "class KenyanFood13Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, *args):\n",
    "    ....\n",
    "    ...\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "    ...\n",
    "    ...\n",
    "    \n",
    "    \n",
    "```\n",
    "\n",
    "```\n",
    "def get_data(args1, *agrs):\n",
    "    ....\n",
    "    ....\n",
    "    return train_loader, test_loader\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3-BZj-t43-5x"
   },
   "outputs": [],
   "source": [
    "class KenyanFood13Data:\n",
    "    \"\"\"\n",
    "    This class parses the KenyanFood13's test.csv and train.csv files and divides the training data\n",
    "    into training and validation sets preserving the relative ratios of the number of images of each\n",
    "    class type.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_root, valid_size = 0.2, random_seed = 42):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # the root path of the images\n",
    "        self.__image_root = os.path.join(data_root, 'images', 'images')\n",
    "        \n",
    "        # parse the test CSV file to obtain filenames (labels are not given)\n",
    "        test_data_frame = self.__parse_data_file(data_root, 'test.csv')\n",
    "        self.__test_fnames = test_data_frame.values[:,0]\n",
    "        \n",
    "        # parse the train CSV file to obtain filenames and labels       \n",
    "        train_data_frame = self.__parse_data_file(data_root, 'train.csv')\n",
    "        fnames = train_data_frame.values[:,0]\n",
    "        labels = train_data_frame.values[:,1]\n",
    "        \n",
    "        # get the classes and class counts\n",
    "        self.__classes, self.__class_counts = np.unique(labels, return_counts=True)\n",
    "        num_classes = len(self.__classes)\n",
    "        \n",
    "        # create a dictionary of text labels to integer labels\n",
    "        label_dict = {}\n",
    "        for key, value in zip(self.__classes, np.arange(num_classes)):\n",
    "            label_dict[key] = value\n",
    "                \n",
    "        # convert the text labels to their numeric equivalents\n",
    "        labels = [label_dict[label] for label in labels]\n",
    "\n",
    "        # retain the complete unsplit training dataset for visualization purposes\n",
    "        self.__unsplit_fnames = fnames\n",
    "        self.__unsplit_labels = labels\n",
    "\n",
    "        # create a dictionary library that stores list of images of the same label\n",
    "        self.__library = {key : [fname for fname, label in zip(fnames, labels) if label == key] \n",
    "                          for key in range(num_classes)}\n",
    "\n",
    "        # split the training data into training and validation sets\n",
    "        self.__train_fnames, self.__valid_fnames, self.__train_labels, self.__valid_labels = train_test_split(\n",
    "            fnames,                      # image file names w/o path or extension\n",
    "            labels,                      # image labels\n",
    "            test_size = valid_size,      # test size\n",
    "            random_state = random_seed,  # random seed for reproducibility\n",
    "            shuffle = True,              # shuffle data before splitting into training and validation sets\n",
    "            stratify = labels            # maintain equal class representation in training and validation sets\n",
    "        )\n",
    "\n",
    "        # create subsets of the training and validation sets for pipeline check\n",
    "        subset_size = 256.0 / len(self.__train_fnames)\n",
    "\n",
    "        _, self.__train_fnames_subset, _, self.__train_labels_subset = train_test_split(\n",
    "            self.__train_fnames,\n",
    "            self.__train_labels,\n",
    "            test_size = subset_size,\n",
    "            random_state = random_seed,\n",
    "            shuffle = True,\n",
    "            stratify = self.__train_labels\n",
    "        )\n",
    "\n",
    "        _, self.__valid_fnames_subset, _, self.__valid_labels_subset = train_test_split(\n",
    "            self.__valid_fnames,\n",
    "            self.__valid_labels,\n",
    "            test_size = subset_size,\n",
    "            random_state = random_seed,\n",
    "            shuffle = True,\n",
    "            stratify = self.__valid_labels\n",
    "        )\n",
    "\n",
    "        \n",
    "    def __parse_data_file(self, data_root, file):\n",
    "        path = os.path.join(data_root, file)\n",
    "        return pd.read_csv(path, delimiter=',', dtype={'id': 'str'}, engine='python')\n",
    "    \n",
    "    @property\n",
    "    def image_root(self):\n",
    "        return self.__image_root\n",
    "\n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self.__classes\n",
    "    \n",
    "    @property\n",
    "    def class_counts(self):\n",
    "        return self.__class_counts\n",
    "    \n",
    "    @property\n",
    "    def test_fnames(self):\n",
    "        return self.__test_fnames\n",
    "    \n",
    "    @property\n",
    "    def train_fnames(self):\n",
    "        return self.__train_fnames\n",
    "    \n",
    "    @property\n",
    "    def train_labels(self):\n",
    "        return self.__train_labels\n",
    "    \n",
    "    @property\n",
    "    def valid_fnames(self):\n",
    "        return self.__valid_fnames\n",
    "    \n",
    "    @property\n",
    "    def valid_labels(self):\n",
    "        return self.__valid_labels\n",
    "\n",
    "    @property\n",
    "    def train_fnames_subset(self):\n",
    "        return self.__train_fnames_subset\n",
    "    \n",
    "    @property\n",
    "    def train_labels_subset(self):\n",
    "        return self.__train_labels_subset\n",
    "    \n",
    "    @property\n",
    "    def valid_fnames_subset(self):\n",
    "        return self.__valid_fnames_subset\n",
    "    \n",
    "    @property\n",
    "    def valid_labels_subset(self):\n",
    "        return self.__valid_labels_subset\n",
    "\n",
    "    @property\n",
    "    def unsplit_fnames(self):\n",
    "        return self.__unsplit_fnames\n",
    "    \n",
    "    @property\n",
    "    def unsplit_labels(self):\n",
    "        return self.__unsplit_labels\n",
    "\n",
    "    @property\n",
    "    def library(self):\n",
    "          return self.__library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRUlCSI_3-5y"
   },
   "outputs": [],
   "source": [
    "class KenyanFood13Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    This custom PyTorch dataset contains images and classification labels from\n",
    "    Kaggle's KenyanFood13 dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_root, fnames, labels=None, transform=None):\n",
    "        super().__init__()\n",
    "        self.__fnames = fnames\n",
    "        self.__labels = labels\n",
    "        self.__transform = transform\n",
    "        self.__image_root = image_root\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the dataset's length, i.e., the number of image/label pairs.\n",
    "        \"\"\"\n",
    "\n",
    "        return len(self.__fnames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns the (optionally resized & preprocessed) image that corresponds to the specified index.\n",
    "        \"\"\"\n",
    "\n",
    "        # conversion needed to remove alpha channel, if present\n",
    "        path = os.path.join(self.__image_root, self.__fnames[idx] + \".jpg\")\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        \n",
    "        if self.__transform is not None:\n",
    "            image = self.__transform(image)\n",
    "\n",
    "        if self.__labels is not None:\n",
    "            extra = self.__labels[idx]  # return target with image\n",
    "        else:\n",
    "            extra = self.__fnames[idx]  # return filename with image\n",
    "\n",
    "        return image, extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrW3bvsx3-5y"
   },
   "outputs": [],
   "source": [
    " def get_datasets(\n",
    "    data: KenyanFood13Data,\n",
    "    test_transforms,\n",
    "    train_transforms,\n",
    "    subset = False\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates datasets for the training, validation, and testing.\n",
    "    \"\"\"\n",
    "\n",
    "    if not subset:\n",
    "\n",
    "        train_dataset = KenyanFood13Dataset(\n",
    "            image_root = data.image_root, \n",
    "            fnames = data.train_fnames, \n",
    "            labels = data.train_labels, \n",
    "            transform = train_transforms)\n",
    "\n",
    "        valid_dataset = KenyanFood13Dataset(\n",
    "            image_root = data.image_root, \n",
    "            fnames = data.valid_fnames, \n",
    "            labels = data.valid_labels, \n",
    "            transform = test_transforms)\n",
    "\n",
    "\n",
    "    else:\n",
    "        \n",
    "        train_dataset = KenyanFood13Dataset(\n",
    "            image_root = data.image_root, \n",
    "            fnames = data.train_fnames_subset, \n",
    "            labels = data.train_labels_subset, \n",
    "            transform = train_transforms)\n",
    "\n",
    "        valid_dataset = KenyanFood13Dataset(\n",
    "            image_root = data.image_root, \n",
    "            fnames = data.valid_fnames_subset, \n",
    "            labels = data.valid_labels_subset, \n",
    "            transform = test_transforms)\n",
    "\n",
    "    test_dataset = KenyanFood13Dataset(\n",
    "        image_root = data.image_root, \n",
    "        fnames = data.test_fnames, \n",
    "        transform = test_transforms)\n",
    "\n",
    "    return train_dataset, valid_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zvtvn0vO3-5z"
   },
   "outputs": [],
   "source": [
    "def get_data_loaders(\n",
    "    train_dataset: Dataset,\n",
    "    valid_dataset: Dataset,\n",
    "    test_dataset: Dataset,\n",
    "    batch_size = 16, \n",
    "    num_workers = 2\n",
    "):\n",
    "    \"\"\"\n",
    "    This function creates and returns the training and validation data loaders.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_data_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=num_workers, \n",
    "        shuffle=True)\n",
    "    \n",
    "    valid_data_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=num_workers, \n",
    "        shuffle=False)\n",
    "\n",
    "    test_data_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset, \n",
    "        batch_size=batch_size, \n",
    "        num_workers=num_workers, \n",
    "        shuffle=False)\n",
    "    \n",
    "\n",
    "    return train_data_loader, valid_data_loader, test_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ONTK53m3-5z"
   },
   "outputs": [],
   "source": [
    "def get_mean_std(data_loader=None):\n",
    "    \"\"\"\n",
    "    Computes the mean and standard deviation. Since this method takes a long\n",
    "    time to run and the data for this workbook is fixed, this method was run\n",
    "    once and its result was copied to the normalization transform.\n",
    "    \"\"\"\n",
    "    \n",
    "    if data_loader is None:\n",
    "        \"\"\"\n",
    "        Returns the mean and standard deviation used by the pretrained\n",
    "        classification models.\n",
    "        \"\"\"\n",
    "\n",
    "        mean = [0.485, 0.456, 0.406] \n",
    "        std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    else:\n",
    "        \"\"\"\n",
    "        Computes the mean and standard deviation of the images returned\n",
    "        by the specified data loader. \n",
    "        \n",
    "        For comparision, the mean and standard deviation of the KenyanFood13\n",
    "        images using the train_dataset and preprocess transforms is as follows.\n",
    "        \n",
    "            mean = [0.5778, 0.4631, 0.3471], \n",
    "            std = [0.2380, 0.2461, 0.2464]):\n",
    "        \"\"\"\n",
    "        \n",
    "        std = 0.\n",
    "        mean = 0.\n",
    "        for images, _ in data_loader:\n",
    "            batch_samples = images.size(0)\n",
    "            images = images.view(batch_samples, images.size(1), -1)\n",
    "            std += images.std(2).sum(0)\n",
    "            mean += images.mean(2).sum(0)\n",
    "        std /= len(data_loader.dataset)\n",
    "        mean /= len(data_loader.dataset)\n",
    "\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnyICYmG-U-B"
   },
   "outputs": [],
   "source": [
    "class ImageTransforms:\n",
    "    \"\"\"\n",
    "    This utility class has methods to create transforms used to train and evaluate a model as\n",
    "    well as visualize images.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            resize = 256, \n",
    "            crop_size = 224, \n",
    "            mean = [0.485, 0.456, 0.406], \n",
    "            std = [0.229, 0.224, 0.225],\n",
    "            config = DataAugConfig()\n",
    "        ):\n",
    "        self.__resize = resize\n",
    "        self.__crop_size = crop_size\n",
    "        self.__mean = mean\n",
    "        self.__std = std\n",
    "        self.__config = config\n",
    "\n",
    "    def preprocess(self, augment=False):\n",
    "        \"\"\"\n",
    "        These transformations convert PIL images to uniformly sized tensors whose dimensions\n",
    "        are crop_size x crop_size pixels. If the augment parameter is True, then the following\n",
    "        data augmentation transforms are applied: color jitter, horizontal flip, vertical flip,\n",
    "        rotation, translation, scaling, and erasing.\n",
    "        \"\"\"\n",
    "        return transforms.Compose(self.__create_transform_list(normalize=False, augment=augment))\n",
    "    \n",
    "    def common(self):\n",
    "        \"\"\"\n",
    "        These transformations convert PIL images to uniformly sized tensors whose dimensions\n",
    "        are crop_size x crop_size pixels and values are normalized by the mean and standard\n",
    "        deviation.\n",
    "        \"\"\"\n",
    "        return transforms.Compose(self.__create_transform_list(normalize=True, augment=False))\n",
    "    \n",
    "    def augment(self):\n",
    "        \"\"\"\n",
    "        These transformations convert PIL images to uniformly sized tensors whose dimensions\n",
    "        are crop_size x crop_size pixels and values are normalized by the mean and standard\n",
    "        deviation with the following data random augmentations: color jitter, horizontal flip,\n",
    "        vertical flip, rotation, translation, scaling, and erasing.\n",
    "        \"\"\"\n",
    "        return transforms.Compose(self.__create_transform_list(normalize=True, augment=True))\n",
    "\n",
    "    def __create_transform_list(self, normalize, augment):\n",
    "        tlist = []\n",
    "\n",
    "        # resize before data augmentation to reduce execution time\n",
    "        tlist.append(transforms.Resize(\n",
    "            size = self.__resize, \n",
    "            interpolation = PIL.Image.BILINEAR\n",
    "        ))\n",
    "\n",
    "        if augment:\n",
    "            # apply rotation before center cropping to avoid \"corner voids\"\n",
    "            tlist.extend(self.__get_color_jitter())\n",
    "            tlist.extend(self.__get_random_vertical_flip())\n",
    "            tlist.extend(self.__get_random_horizontal_flip())\n",
    "            tlist.extend(self.__get_random_affine())\n",
    "\n",
    "        tlist.append(transforms.CenterCrop(self.__crop_size))\n",
    "        tlist.append(transforms.ToTensor())\n",
    "\n",
    "        if normalize:\n",
    "            tlist.append(transforms.Normalize(self.__mean, self.__std, inplace=True))\n",
    "\n",
    "        if augment:\n",
    "            tlist.extend(self.__get_random_erasing())\n",
    "\n",
    "        return tlist\n",
    "\n",
    "    def __get_color_jitter(self):\n",
    "        tlist = []\n",
    "        if self.__config.color_enabled:\n",
    "            tlist.append(transforms.ColorJitter(\n",
    "                brightness = self.__config.color_brightness, \n",
    "                contrast = self.__config.color_contrast, \n",
    "                saturation = self.__config.color_saturation, \n",
    "                hue = self.__config.color_hue\n",
    "            ))\n",
    "        return tlist\n",
    "\n",
    "    def __get_random_vertical_flip(self):\n",
    "        tlist = []\n",
    "        if self.__config.vert_flip_prob > 0:\n",
    "            tlist.append(transforms.RandomVerticalFlip(\n",
    "                p=self.__config.vert_flip_prob\n",
    "            ))\n",
    "        return tlist \n",
    "\n",
    "    def __get_random_horizontal_flip(self):\n",
    "        tlist = []\n",
    "        if self.__config.horz_flip_prob > 0:\n",
    "            tlist.append(transforms.RandomHorizontalFlip(\n",
    "                p=self.__config.horz_flip_prob\n",
    "            ))\n",
    "        return tlist \n",
    "\n",
    "    def __get_random_affine(self):\n",
    "        tlist = []\n",
    "        if self.__config.affine_enabled:\n",
    "            tlist.append(transforms.RandomAffine(\n",
    "                degrees = self.__config.affine_rotation,\n",
    "                translate = self.__config.affine_translate,\n",
    "                scale = self.__config.affine_scale,\n",
    "                resample=PIL.Image.BILINEAR\n",
    "            ))\n",
    "        return tlist\n",
    "\n",
    "    def __get_random_erasing(self):\n",
    "        tlist = []\n",
    "        if self.__config.erasing_prob > 0:\n",
    "            tlist.append(transforms.RandomErasing(\n",
    "                p = self.__config.erasing_prob,\n",
    "                scale = self.__config.erasing_scale,\n",
    "                ratio = self.__config.erasing_ratio,\n",
    "                inplace = True\n",
    "            ))\n",
    "        return tlist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaqNIzTm3-5z"
   },
   "source": [
    "## <font style=\"color:green\">2. Configuration [5 Points]</font>\n",
    "\n",
    "Define your configuration in this section.\n",
    "\n",
    "For example,\n",
    "\n",
    "```\n",
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 10 \n",
    "    epochs_count: int = 50  \n",
    "    init_learning_rate: float = 0.1  # initial learning rate for lr scheduler\n",
    "    log_interval: int = 5  \n",
    "    test_interval: int = 1  \n",
    "    data_root: str = \"/kaggle/input/pytorch-opencv-course-classification/\" \n",
    "    num_workers: int = 2  \n",
    "    device: str = 'cuda'  \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__6DBlJp3-5z"
   },
   "source": [
    "## <font style=\"color:blue\">Assignment Response</font>\n",
    "\n",
    "Since I am using the <b>trainer</b> module, I made minor modifications to the <u>configuration.py</u> file. In addition, I created a master <i>MasterConfig</i> data class that encapsulates the individual configuration data classes. Following, I created helper functions to instantiate the <i>MasterConfig</i> class with experiment-specific overrides.\n",
    "\n",
    "The following is the output of the <code>create_master_config</code> method w/o any parameter overrides.\n",
    "\n",
    "<u>Note</u>: Replaced nested compose blocks with a linear iterable and removed transform parameters for brevity.\n",
    "\n",
    "<pre>\n",
    "MasterConfig(\n",
    "    system=SystemConfig(\n",
    "        proj_dir='./project2', \n",
    "        seed=42, \n",
    "        cudnn_deterministic=True, \n",
    "        cudnn_benchmark_enabled=False\n",
    "    ), \n",
    "    dataset=DatasetConfig(\n",
    "        data_dir='./project2/data', \n",
    "        valid_size=0.2, \n",
    "        train_transforms=Iterable[Callable] = (\n",
    "            ColorJitter( ... ),\n",
    "            RandomVerticalFlip( ... ),\n",
    "            RandomHorizontalFlip( ... ),\n",
    "            RandomAffine( ... ),\n",
    "            Resize( ... ),\n",
    "            CenterCrop( ... ),\n",
    "            ToTensor(),\n",
    "            Normalize( ... ),\n",
    "            RandomErasing()\n",
    "        ), \n",
    "        test_transforms=Iterable[Callable] = (\n",
    "            Resize( ... ),\n",
    "            CenterCrop( ... ),\n",
    "            ToTensor(),\n",
    "            Normalize( ... ),\n",
    "        ), \n",
    "        visual_transforms=Iterable[Callable] = (\n",
    "            Resize( ... ),\n",
    "            CenterCrop( ... ),\n",
    "            ToTensor(),\n",
    "        )\n",
    "    ), \n",
    "    data_loader=DataLoaderConfig(\n",
    "        batch_size=32, \n",
    "        num_workers=4\n",
    "    ), \n",
    "    optimizer=OptimizerConfig(\n",
    "        learning_rate=0.001, \n",
    "        momentum=0.9, \n",
    "        weight_decay=0.0001, \n",
    "        betas=(0.9, 0.999)\n",
    "    ), \n",
    "    scheduler=SchedulerConfig(\n",
    "        gamma=0.1, \n",
    "        step_size=10, \n",
    "        milestones=(20, 30, 40), \n",
    "        patience=10, \n",
    "        threshold=0.0001\n",
    "    ), \n",
    "    trainer=TrainerConfig(\n",
    "        device='cuda', \n",
    "        training_epochs=50, \n",
    "        progress_bar=True, \n",
    "        model_dir='models', \n",
    "        model_saving_period=0, \n",
    "        visualizer_dir='runs', \n",
    "        stop_loss_epochs=0, \n",
    "        stop_acc_epochs=0, \n",
    "        stop_acc_ema_alpha=0.3, \n",
    "        stop_acc_threshold=2.0\n",
    "    )\n",
    ")\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QisAY1BO-U-C"
   },
   "outputs": [],
   "source": [
    "def create_system_config():\n",
    "    return SystemConfig(\n",
    "        proj_dir = proj_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_aug_config(\n",
    "    color_enabled: bool = None,\n",
    "    color_brightness: Tuple[float, float] = None,\n",
    "    color_contrast: Tuple[float, float] = None,\n",
    "    color_saturation: Tuple[float, float] = None,\n",
    "    color_hue: Tuple[float, float] = None,\n",
    "    horz_flip_prob: float = None,\n",
    "    vert_flip_prob: float = None,\n",
    "    affine_enabled: bool = None,\n",
    "    affine_rotation: float = None,\n",
    "    affine_translate: Tuple[float, float] = None,\n",
    "    affine_scale: Tuple[float, float] = None,\n",
    "    erasing_prob: float = None,\n",
    "    erasing_scale: Tuple[float, float] = None,\n",
    "    erasing_ratio: Tuple[float, float] = None\n",
    "):\n",
    "    config = DataAugConfig()\n",
    "    if color_enabled is None:\n",
    "        color_enabled = config.color_enabled\n",
    "    if color_brightness is None:\n",
    "        color_brightness = config.color_brightness\n",
    "    if color_contrast is None:\n",
    "        color_contrast = config.color_contrast\n",
    "    if color_saturation is None:\n",
    "        color_saturation = config.color_saturation\n",
    "    if color_hue is None:\n",
    "        color_hue = config.color_hue\n",
    "    if horz_flip_prob is None:\n",
    "        horz_flip_prob = config.horz_flip_prob\n",
    "    if vert_flip_prob is None:\n",
    "        vert_flip_prob = config.vert_flip_prob\n",
    "    if affine_enabled is None:\n",
    "        affine_enabled = config.affine_enabled\n",
    "    if affine_rotation is None:\n",
    "        affine_rotation = config.affine_rotation\n",
    "    if affine_translate is None:\n",
    "        affine_translate = config.affine_translate\n",
    "    if affine_scale is None:\n",
    "        affine_scale = config.affine_scale\n",
    "    if erasing_prob is None:\n",
    "        erasing_prob = config.erasing_prob\n",
    "    if erasing_scale is None:\n",
    "        erasing_scale = config.erasing_scale\n",
    "    if erasing_ratio is None:\n",
    "        erasing_ratio = config.erasing_ratio\n",
    "    return DataAugConfig(\n",
    "        color_enabled = color_enabled,\n",
    "        color_brightness = color_brightness,\n",
    "        color_contrast = color_contrast,\n",
    "        color_saturation = color_saturation,\n",
    "        color_hue = color_hue,\n",
    "        horz_flip_prob = horz_flip_prob,\n",
    "        vert_flip_prob = vert_flip_prob,\n",
    "        affine_enabled = affine_enabled,\n",
    "        affine_rotation = affine_rotation,\n",
    "        affine_translate = affine_translate,\n",
    "        affine_scale = affine_scale,\n",
    "        erasing_prob = erasing_prob,\n",
    "        erasing_scale = erasing_scale,\n",
    "        erasing_ratio = erasing_ratio\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_config(\n",
    "    resize: int = 256, \n",
    "    crop_size: int = 224,\n",
    "    data_aug_config = DataAugConfig()\n",
    "):\n",
    "    mean, std = get_mean_std()\n",
    "    transforms = ImageTransforms(\n",
    "        resize = resize, \n",
    "        crop_size = crop_size, \n",
    "        mean = mean, \n",
    "        std = std,\n",
    "        config = data_aug_config\n",
    "    )\n",
    "    return DatasetConfig(\n",
    "        data_dir = data_dir,\n",
    "        test_transforms = transforms.common(),\n",
    "        train_transforms = transforms.augment(),\n",
    "        visual_transforms = transforms.preprocess(augment=False),\n",
    "        visual_aug_transforms = transforms.preprocess(augment=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader_config(\n",
    "    batch_size: int = None, \n",
    "    num_workers: int = None\n",
    "):\n",
    "    config = DataLoaderConfig()\n",
    "    if batch_size is None:\n",
    "        batch_size = config.batch_size\n",
    "    if num_workers is None:\n",
    "        num_workers = config.num_workers\n",
    "    return DataLoaderConfig(\n",
    "        batch_size = batch_size,\n",
    "        num_workers = num_workers\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer_config(\n",
    "    learning_rate: float = None, \n",
    "    momentum: float = None, \n",
    "    weight_decay: float = None,\n",
    "    betas: Tuple[float, float] = None\n",
    "):\n",
    "    config = OptimizerConfig()\n",
    "    if learning_rate is None:\n",
    "        learning_rate = config.learning_rate\n",
    "    if momentum is None:\n",
    "        momentum = config.momentum\n",
    "    if weight_decay is None:\n",
    "        weight_decay = config.weight_decay\n",
    "    if betas is None:\n",
    "        betas = config.betas\n",
    "    return OptimizerConfig(\n",
    "        learning_rate = learning_rate,\n",
    "        momentum = momentum,\n",
    "        weight_decay = weight_decay,\n",
    "        betas = betas\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scheduler_config(\n",
    "    gamma: float = None,\n",
    "    step_size: int = None,\n",
    "    milestones: Iterable = None,\n",
    "    patience: int = None,\n",
    "    threshold: float = None\n",
    "):\n",
    "    config = SchedulerConfig()\n",
    "    if gamma is None:\n",
    "        gamma = config.gamma\n",
    "    if step_size is None:\n",
    "        step_size = config.step_size\n",
    "    if milestones is None:\n",
    "        milestones = config.milestones\n",
    "    if patience is None:\n",
    "        patience = config.patience\n",
    "    if threshold is None:\n",
    "        threshold = config.threshold\n",
    "    return SchedulerConfig(\n",
    "        gamma = gamma,\n",
    "        step_size = step_size,\n",
    "        milestones = milestones,\n",
    "        patience = patience,\n",
    "        threshold = threshold\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trainer_config(\n",
    "    training_epochs: int = None,\n",
    "    stop_loss_epochs: int = None,\n",
    "    stop_acc_epochs: int = None, \n",
    "    stop_acc_ema_alpha: float = None,\n",
    "    stop_acc_threshold: float = None\n",
    "):\n",
    "    config = TrainerConfig()\n",
    "    if training_epochs is None:\n",
    "        training_epochs = config.training_epochs\n",
    "    if stop_loss_epochs is None:\n",
    "        stop_loss_epochs = config.stop_loss_epochs\n",
    "    if stop_acc_epochs is None:\n",
    "        stop_acc_epochs = config.stop_acc_epochs\n",
    "    if stop_acc_ema_alpha is None:\n",
    "        stop_acc_ema_alpha = config.stop_acc_ema_alpha\n",
    "    if stop_acc_threshold is None:\n",
    "        stop_acc_threshold = config.stop_acc_threshold\n",
    "    return TrainerConfig(\n",
    "        training_epochs = training_epochs,\n",
    "        stop_loss_epochs = stop_loss_epochs,\n",
    "        stop_acc_epochs = stop_acc_epochs,\n",
    "        stop_acc_ema_alpha = stop_acc_ema_alpha,\n",
    "        stop_acc_threshold = stop_acc_threshold\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hi4_VFrx3-50"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MasterConfig:\n",
    "    system: SystemConfig = create_system_config()\n",
    "    data_aug: DataAugConfig = create_data_aug_config()\n",
    "    dataset: DatasetConfig = create_dataset_config()\n",
    "    data_loader: DataLoaderConfig = create_data_loader_config()\n",
    "    optimizer: OptimizerConfig = create_optimizer_config()\n",
    "    scheduler: SchedulerConfig = create_scheduler_config()\n",
    "    trainer: TrainerConfig = create_trainer_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HPBi-DL-U-C"
   },
   "outputs": [],
   "source": [
    "def create_master_config(\n",
    "    transform_resize: int = 256,\n",
    "    transform_crop_size: int = 224,\n",
    "    data_aug_color_enabled: bool = None,\n",
    "    data_aug_color_brightness: Tuple[float, float] = None,\n",
    "    data_aug_color_contrast: Tuple[float, float] = None,\n",
    "    data_aug_color_saturation: Tuple[float, float] = None,\n",
    "    data_aug_color_hue: Tuple[float, float] = None,\n",
    "    data_aug_horz_flip_prob: float = None,\n",
    "    data_aug_vert_flip_prob: float = None,\n",
    "    data_aug_affine_enabled: bool = None,\n",
    "    data_aug_affine_rotation: float = None,\n",
    "    data_aug_affine_translate: Tuple[float, float] = None,\n",
    "    data_aug_affine_scale: Tuple[float, float] = None,\n",
    "    data_aug_erasing_prob: float = None,\n",
    "    data_aug_erasing_scale: Tuple[float, float] = None,\n",
    "    data_aug_erasing_ratio: Tuple[float, float] = None,\n",
    "    data_loader_batch_size: int = None,\n",
    "    data_loader_num_workers: int = None,\n",
    "    optimzer_learning_rate: float = None,\n",
    "    optimzer_momentum: float = None,\n",
    "    optimzer_weight_decay: float = None,\n",
    "    optimzer_betas: Tuple[float, float] = None,\n",
    "    lr_scheduler_gamma: float = None,\n",
    "    lr_scheduler_step_size: int = None,\n",
    "    lr_scheduler_milestones: Iterable = None,\n",
    "    lr_scheduler_patience: int = None,\n",
    "    lr_scheduler_threshold: float = None,\n",
    "    trainer_training_epochs: int = None,\n",
    "    trainer_stop_loss_epochs: int = None,\n",
    "    trainer_stop_acc_epochs: int = None,\n",
    "    trainer_stop_acc_ema_alpha: float = None,\n",
    "    trainer_stop_acc_threshold: float = None       \n",
    ") -> MasterConfig:\n",
    "    # used to initialize MasterConfig data class and as a parameter to the\n",
    "    # create_data_config function\n",
    "    data_aug_config = create_data_aug_config(\n",
    "        data_aug_color_enabled,\n",
    "        data_aug_color_brightness,\n",
    "        data_aug_color_contrast,\n",
    "        data_aug_color_saturation,\n",
    "        data_aug_color_hue,\n",
    "        data_aug_horz_flip_prob,\n",
    "        data_aug_vert_flip_prob,\n",
    "        data_aug_affine_enabled,\n",
    "        data_aug_affine_rotation,\n",
    "        data_aug_affine_translate,\n",
    "        data_aug_affine_scale,\n",
    "        data_aug_erasing_prob,\n",
    "        data_aug_erasing_scale,\n",
    "        data_aug_erasing_ratio\n",
    "    )\n",
    "    return MasterConfig(\n",
    "        system = create_system_config(),\n",
    "        data_aug = data_aug_config,\n",
    "        dataset = create_dataset_config(\n",
    "            transform_resize,\n",
    "            transform_crop_size,\n",
    "            data_aug_config\n",
    "        ),\n",
    "        data_loader = create_data_loader_config(\n",
    "            data_loader_batch_size,\n",
    "            data_loader_num_workers\n",
    "        ),\n",
    "        optimizer = create_optimizer_config(\n",
    "            optimzer_learning_rate,\n",
    "            optimzer_momentum,\n",
    "            optimzer_weight_decay,\n",
    "            optimzer_betas\n",
    "        ),\n",
    "        scheduler = create_scheduler_config(\n",
    "            lr_scheduler_gamma,\n",
    "            lr_scheduler_step_size,\n",
    "            lr_scheduler_milestones,\n",
    "            lr_scheduler_patience,\n",
    "            lr_scheduler_threshold   \n",
    "        ),\n",
    "        trainer = create_trainer_config(\n",
    "            trainer_training_epochs,\n",
    "            trainer_stop_loss_epochs,\n",
    "            trainer_stop_acc_epochs,\n",
    "            trainer_stop_acc_ema_alpha,\n",
    "            trainer_stop_acc_threshold       \n",
    "        )\n",
    "    )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PYVGcNyX3-50"
   },
   "source": [
    "## <font style=\"color:green\">3. Evaluation Metric [10 Points]</font>\n",
    "\n",
    "Define methods or classes that will be used in model evaluation, for example, accuracy, f1-score, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJg9CPFB3-50"
   },
   "source": [
    "### <font style=\"color:blue\">Loss Function</font>\n",
    "\n",
    "The number of images per class are unequal; thus, a weighted cross-entropy loss function should be used.\n",
    "\n",
    "The number of images per class were obtained via the following code.<code>\n",
    "\n",
    "    data = KenyanFood13Data(...)\n",
    "    images_per_class = np.column_stack((data.classes, data.class_counts))\n",
    "    print(images_per_class)\n",
    "\n",
    "    [['bhaji' 632]\n",
    "     ['chapati' 862]\n",
    "     ['githeri' 479]\n",
    "     ['kachumbari' 494]\n",
    "     ['kukuchoma' 173]\n",
    "     ['mandazi' 620]\n",
    "     ['masalachips' 438]\n",
    "     ['matoke' 483]\n",
    "     ['mukimo' 212]\n",
    "     ['nyamachoma' 784]\n",
    "     ['pilau' 329]\n",
    "     ['sukumawiki' 402]\n",
    "     ['ugali' 628]]\n",
    "</code>\n",
    "\n",
    "The rescaling weights given to each class were obtained via the following code.<code>\n",
    "\n",
    "    rescaling_weights = data.class_counts / np.sum(data.class_counts)\n",
    "    print(rescaling_weights)\n",
    "    \n",
    "    [0.09669523 0.13188494 0.07328641 0.0755814  0.02646879 0.09485924\n",
    "     0.06701346 0.07389841 0.03243574 0.11995104 0.0503366  0.06150551\n",
    "     0.09608323]\n",
    "</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qW__PU7F3-50"
   },
   "outputs": [],
   "source": [
    "weighted_cross_entropy_loss = nn.CrossEntropyLoss(\n",
    "    weight=torch.tensor([\n",
    "        0.09669523, 0.13188494, 0.07328641, 0.0755814,  0.02646879, \n",
    "        0.09485924, 0.06701346, 0.07389841, 0.03243574, 0.11995104, \n",
    "        0.0503366, 0.06150551, 0.09608323\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kQjdvYWV3-50"
   },
   "source": [
    "### <font style=\"color:blue\">Metric Function</font>\n",
    "\n",
    "We are going to use the <b>trainer</b> module's <i>AccuracyEstimator</i> class from <u>metrics.py</u> file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sSIXHXg3-51"
   },
   "source": [
    "## <font style=\"color:green\">4. Train and Validation [5 Points]</font>\n",
    "\n",
    "Write the methods or classes that will be used for training and validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YhF41hAH3-51"
   },
   "source": [
    "## <font style=\"color:blue\">Assignment Response</font>\n",
    "\n",
    "Since I am using the <b>trainer</b> module, I made the following modifications to the <u>trainer.py</u> file.\n",
    "<ul>\n",
    "    <li>Added the ability to save the model only when the test loss reaches a new minimum.</li>\n",
    "    <li>Added the ability to terminate training after a specified number of epochs where the test loss is not further reduced.</li>\n",
    "    <li>Added the ability to terminate training after a specified number of epochs where the exponential moving average of the test loss does not significantly increase.</li>\n",
    "</ul>\n",
    "\n",
    "I made the following modifications to the <u>visualizer.py</u> and <u>tensorboard_visualizer.py</u> files.\n",
    "<ul>\n",
    "    <li>Added an <code>add_image(self, tag, image)</code> method to visualize the dataset.\n",
    "    <li>Added an <code>add_graph(self, model, images)</code> method to document the model.</li>\n",
    "    <li>Added an <code>add_pr_curves(self, classes, pred_probs, targets)</code> method to document the precision-recall curves of the fully trained model for each class type.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mxi77QT13-51"
   },
   "outputs": [],
   "source": [
    "class Optimizer(Enum):\n",
    "    SGD = auto()\n",
    "    ADAM = auto()\n",
    "    \n",
    "def get_optimizer(\n",
    "    model: nn.Module,\n",
    "    optimizer: Optimizer = Optimizer.SGD,\n",
    "    config: OptimizerConfig = OptimizerConfig()\n",
    "):\n",
    "    \"\"\"\n",
    "    Gets the specified optimzer.\n",
    "    \"\"\"\n",
    "    \n",
    "    if optimizer == Optimizer.SGD:\n",
    "        return optim.SGD(\n",
    "            model.parameters(),\n",
    "            lr = config.learning_rate,\n",
    "            weight_decay = config.weight_decay,\n",
    "            momentum = config.momentum\n",
    "        )\n",
    "    \n",
    "    elif optimizer == Optimizer.ADAM:\n",
    "        return optim.Adam(\n",
    "            model.parameters(),\n",
    "            lr = config.learning_rate,\n",
    "            betas = config.betas\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise SystemExit(\"Invalid lr_scheduler value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ji0-7_V_3-51"
   },
   "outputs": [],
   "source": [
    "class LrScheduler(Enum):\n",
    "    STEP = auto()\n",
    "    MULTI_STEP = auto()\n",
    "    EXPONENTIAL = auto()\n",
    "    REDUCE_ON_PLATEAU = auto()\n",
    "    \n",
    "def get_lr_scheduler(\n",
    "    optimizer: optim.Optimizer,\n",
    "    lr_scheduler: LrScheduler = LrScheduler.STEP,\n",
    "    config: SchedulerConfig = SchedulerConfig()\n",
    "):\n",
    "    \"\"\"\n",
    "    Gets the specified LR scheduler.\n",
    "    \"\"\"\n",
    "\n",
    "    if lr_scheduler == LrScheduler.STEP:\n",
    "        return optim.lr_scheduler.StepLR(\n",
    "            optimizer,\n",
    "            step_size = config.step_size,\n",
    "            gamma = config.gamma\n",
    "        )\n",
    "    \n",
    "    elif lr_scheduler == LrScheduler.MULTI_STEP:\n",
    "        return optim.lr_scheduler.MultiStepLR(\n",
    "            optimizer, \n",
    "            milestones = config.milestones, \n",
    "            gamma = config.gamma\n",
    "        )\n",
    "    \n",
    "    elif lr_scheduler == LrScheduler.EXPONENTIAL:\n",
    "        return optim.lr_scheduler.ExponentialLR(\n",
    "            optimizer, \n",
    "            gamma = config.gamma\n",
    "        )\n",
    "    \n",
    "    \n",
    "    elif lr_scheduler == LrScheduler.REDUCE_ON_PLATEAU:\n",
    "        return optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, \n",
    "            factor = config.gamma,\n",
    "            patience = config.patience,\n",
    "            threshold = config.threshold\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise SystemExit(\"Invalid lr_scheduler value.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DlaX2uwY3-51"
   },
   "outputs": [],
   "source": [
    "def predict_batch(model, data, max_prob=True):\n",
    "    \"\"\"\n",
    "    Get prediction for a batch of data. This function assumes the model and data\n",
    "    have be sent to the appropriate device and the model is in evaluation mode.\n",
    "    \"\"\"\n",
    "\n",
    "    output = model(data)\n",
    "\n",
    "    # get probability score using softmax\n",
    "    prob = F.softmax(output, dim=1)\n",
    "    \n",
    "    if max_prob:\n",
    "        # get the max probability\n",
    "        pred_prob = prob.data.max(dim=1)[0]\n",
    "    else:\n",
    "        # return all probabilties\n",
    "        pred_prob = prob.data\n",
    "    \n",
    "    # get the index of the max probability\n",
    "    pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MtIeeYLzasi-"
   },
   "outputs": [],
   "source": [
    "def get_targets_and_pred_probs(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Get targets and prediction probabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.to(device)  # send model to cpu or cuda\n",
    "    model.eval()      # set model to evaluation mode\n",
    "\n",
    "    targets = []\n",
    "    pred_probs = []\n",
    "\n",
    "    for _, (data, target) in enumerate(dataloader):\n",
    "        _, probs = predict_batch(model, data.to(device), max_prob=False)       \n",
    "        pred_probs.append(probs)\n",
    "        targets.append(target.numpy())\n",
    "        \n",
    "    targets = np.concatenate(targets).astype(int)\n",
    "    pred_probs = np.concatenate(pred_probs, axis=0)\n",
    "    \n",
    "    return targets, pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FezIMZnRvPUZ"
   },
   "outputs": [],
   "source": [
    "def predict_test_data(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Predict the class of the test data.\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)  # send model to cpu or cuda\n",
    "    model.eval()      # set model to evaluation mode\n",
    "\n",
    "    fnames = []\n",
    "    preds = []\n",
    "\n",
    "    for _, (data, fname) in enumerate(dataloader):\n",
    "        pred, _ = predict_batch(model, data.to(device), max_prob=True)       \n",
    "        fnames.append(fname)\n",
    "        preds.append(pred)\n",
    "        \n",
    "    fnames = np.concatenate(fnames)\n",
    "    preds = np.concatenate(preds).astype(int)\n",
    "    \n",
    "    return fnames, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_valid_data(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Predict the class of the validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    model.to(device)  # send model to cpu or cuda\n",
    "    model.eval()      # set model to evaluation mode\n",
    "\n",
    "    targets = []\n",
    "    preds = []\n",
    "\n",
    "    for _, (data, target) in enumerate(dataloader):\n",
    "        pred, _ = predict_batch(model, data.to(device), max_prob=True)       \n",
    "        targets.append(target)\n",
    "        preds.append(pred)\n",
    "        \n",
    "    targets = np.concatenate(targets)\n",
    "    preds = np.concatenate(preds).astype(int)\n",
    "    \n",
    "    return targets, preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ajr4pCOz3-51"
   },
   "source": [
    "## <font style=\"color:green\">5. Model [5 Points]</font>\n",
    "\n",
    "Define your model in this section.\n",
    "\n",
    "**You are allowed to use any pre-trained model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02C_Nwdo7SBK"
   },
   "source": [
    "## <font style=\"color:blue\">Assignment Response</font>\n",
    "\n",
    "My primary objective is to explore fine tuning numerous pretrained models. Hence, I created classes\n",
    "to easily set the \"tuning level\" of the ResNet, VGG, and DenseNet family of TorchVision models. I\n",
    "also want to see how the model I developed for Project 1 performs, so I created as a class for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TuningParam = namedtuple(\"TuningParam\", [\"level\", \"block\", \"layers\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TorchVisionModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Base class for TorchVision models, which provides a method to freeze network\n",
    "    layers allowing fine tuning. This class does change the network's output layer.\n",
    "    Derived classes must do this!\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, network: nn.Module):\n",
    "        super().__init__()\n",
    "        self._network = network\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self._network(x)\n",
    "    \n",
    "    def _freeze_layers(\n",
    "        self, \n",
    "        tuning_params: List[TuningParam], \n",
    "        pretrained:bool, \n",
    "        tuning_level:int\n",
    "    ):\n",
    "        # freeze network if using a pretrained model\n",
    "        if pretrained:\n",
    "            self._set_requires_grad(self._network, False)\n",
    "        \n",
    "        # unfreeze blocks/layers based on tuning_level\n",
    "        for param in tuning_params:\n",
    "            if param.level <= tuning_level:\n",
    "                block = getattr(self._network, param.block)\n",
    "                if param.layers is None:\n",
    "                    self._set_requires_grad(block, True)\n",
    "                else:\n",
    "                    for layer in param.layers:\n",
    "                        if isinstance(layer, int):\n",
    "                            self._set_requires_grad(block[layer], True)\n",
    "                        else:\n",
    "                            self._set_requires_grad(getattr(block, layer), True)\n",
    "            \n",
    "    def _set_requires_grad(self, block, value):\n",
    "        for param in block.parameters():\n",
    "            param.requires_grad = value\n",
    "            \n",
    "    def _inclusive_range(self, start:int, stop:int) -> List[int]:\n",
    "        return list(range(start, stop + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DonDtN5MBBU1"
   },
   "outputs": [],
   "source": [
    "class ResNetBase(TorchVisionModel):\n",
    "    \"\"\"\n",
    "    Base class for ResNet models that may be pretrained and fine tuned. The\n",
    "    tuning_level parameter controls the degree of fine tuning as depicted in\n",
    "    the table below.\n",
    "        \n",
    "        ResNet     tuning_level\n",
    "        -------    ------------\n",
    "        conv1          >= 5        \n",
    "        bn1            >= 5\n",
    "        relu           >= 5\n",
    "        maxpool        >= 5\n",
    "        layer1         >= 4\n",
    "        layer2         >= 3\n",
    "        layer3         >= 2\n",
    "        layer4         >= 1\n",
    "        avgpool        >= 1\n",
    "        fc             >= 0\n",
    "        \n",
    "    If tuning_level = 0, then only the classifier layer is trained.\n",
    "    If tuning_level = 5, then the entire network is trained.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_fn: Callable, pretrained=True, tuning_level=0):\n",
    "        super().__init__(model_fn(pretrained=pretrained))\n",
    "\n",
    "        # change the output layer\n",
    "        last_layer_in = self._network.fc.in_features\n",
    "        self._network.fc = nn.Linear(last_layer_in, 13)\n",
    "\n",
    "        # ToDo: Omit layer types that do not have trainable parameters\n",
    "        tuning_params = [\n",
    "            TuningParam(0, \"fc\", None),\n",
    "            TuningParam(1, \"avgpool\", None),\n",
    "            TuningParam(1, \"layer4\", None),\n",
    "            TuningParam(2, \"layer3\", None),\n",
    "            TuningParam(3, \"layer2\", None),\n",
    "            TuningParam(4, \"layer1\", None),\n",
    "            TuningParam(5, \"maxpool\", None),\n",
    "            TuningParam(5, \"relu\", None),\n",
    "            TuningParam(5, \"bn1\", None),\n",
    "            TuningParam(5, \"conv1\", None)\n",
    "        ]\n",
    "\n",
    "        self._freeze_layers(tuning_params, pretrained, tuning_level)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self._network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDbYluEM3-52"
   },
   "outputs": [],
   "source": [
    "class ResNet18(ResNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.resnet18, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRrkXWSABBU2"
   },
   "outputs": [],
   "source": [
    "class ResNet34(ResNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.resnet34, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qom1WSnGBBU2"
   },
   "outputs": [],
   "source": [
    "class ResNet50(ResNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.resnet50, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dA-QcvSGBBU2"
   },
   "outputs": [],
   "source": [
    "class ResNet101(ResNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.resnet101, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dA-QcvSGBBU2"
   },
   "outputs": [],
   "source": [
    "class ResNet152(ResNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.resnet152, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGTEW_FoBBU2"
   },
   "outputs": [],
   "source": [
    "class ResNeXt50(ResNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.resnext50_32x4d, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1_tKL2_A7Am"
   },
   "outputs": [],
   "source": [
    "class ResNeXt101(ResNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.resnext101_32x8d, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ucBgzJWvA8Rn"
   },
   "outputs": [],
   "source": [
    "class WideResNet50(ResNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.wide_resnet50_2, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ShfGU7oCHvj"
   },
   "outputs": [],
   "source": [
    "class WideResNet101(ResNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.wide_resnet101_2, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2e70wQoxzkgh"
   },
   "outputs": [],
   "source": [
    "class VGGBase(TorchVisionModel):\n",
    "    \"\"\"\n",
    "    Base class for ResNet models that may be pretrained and fine tuned.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_fn: Callable, pretrained=True):\n",
    "        super().__init__(model_fn(pretrained=pretrained))\n",
    "\n",
    "        last_layer_in = self._network.classifier[6].in_features\n",
    "        self._network.classifier[6] = nn.Linear(last_layer_in, 13)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self._network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xkG8GBX8207n"
   },
   "outputs": [],
   "source": [
    "class VGG11BN(VGGBase):\n",
    "    \"\"\"\n",
    "    VGG11BN model that may be pretrained and fine tuned. The tuning_level\n",
    "    parameter controls the degree of fine tuning as depicted in the table\n",
    "    below.\n",
    "    \n",
    "        VGG11_BN            tuning_level\n",
    "        ----------------    ------------\n",
    "        features\n",
    "          [00-02] CNR           >= 5\n",
    "          [03] MaxPool2d        >= 5\n",
    "          [04-06] CNR           >= 4\n",
    "          [07] MaxPool2d        >= 4\n",
    "          [08-10] CNR           >= 3\n",
    "          [11-13] CNR           >= 3\n",
    "          [14] MaxPool2d        >= 3\n",
    "          [15-17] CNR           >= 2\n",
    "          [18-20] CNR           >= 2\n",
    "          [21] MaxPool2d        >= 2\n",
    "          [22-24] CNR           >= 1\n",
    "          [25-27] CNR           >= 1\n",
    "          [28] MaxPool2d        >= 1\n",
    "        avgpool                 >= 1\n",
    "        classifier              \n",
    "          [00-02] LRD           >= 0\n",
    "          [03-05] LRD           >= 0\n",
    "          [06] Linear           >= 0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.vgg11_bn, pretrained)\n",
    "            \n",
    "        # ToDo: Omit layer types that do not have trainable parameters\n",
    "        tuning_params = [\n",
    "            TuningParam(0, \"classifier\", None),\n",
    "            TuningParam(1, \"avgpool\", None),\n",
    "            TuningParam(1, \"features\", self._inclusive_range(22, 28)),\n",
    "            TuningParam(2, \"features\", self._inclusive_range(15, 21)),\n",
    "            TuningParam(3, \"features\", self._inclusive_range(8, 14)),\n",
    "            TuningParam(4, \"features\", self._inclusive_range(4, 7)),\n",
    "            TuningParam(5, \"features\", self._inclusive_range(0, 3))\n",
    "        ]\n",
    "\n",
    "        self._freeze_layers(tuning_params, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f7IyXWM521Jy"
   },
   "outputs": [],
   "source": [
    "class VGG13BN(VGGBase):\n",
    "    \"\"\"\n",
    "    VGG13BN model that may be pretrained and fine tuned. The tuning_level\n",
    "    parameter controls the degree of fine tuning as depicted in the table\n",
    "    below.\n",
    "    \n",
    "        VGG13_BN            tuning_level\n",
    "        ----------------    ------------\n",
    "        features\n",
    "          [00-02] CNR           >= 5\n",
    "          [03-05] CNR           >= 5\n",
    "          [06] MaxPool2d        >= 5\n",
    "          [07-09] CNR           >= 4\n",
    "          [10-12] CNR           >= 4\n",
    "          [13] MaxPool2d        >= 4\n",
    "          [14-16] CNR           >= 3\n",
    "          [17-19] CNR           >= 3\n",
    "          [20] MaxPool2d        >= 3\n",
    "          [21-23] CNR           >= 2\n",
    "          [24-26] CNR           >= 2\n",
    "          [27] MaxPool2d        >= 2\n",
    "          [28-30] CNR           >= 1\n",
    "          [31-33] CNR           >= 1\n",
    "          [34] MaxPool2d        >= 1\n",
    "        avgpool                 >= 1\n",
    "        classifier\n",
    "          [00-02] LRD           >= 0\n",
    "          [03-05] LRD           >= 0\n",
    "          [06] Linear           >= 0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.vgg13_bn, pretrained)\n",
    "            \n",
    "        # ToDo: Omit layer types that do not have trainable parameters\n",
    "        tuning_params = [\n",
    "            TuningParam(0, \"classifier\", None),\n",
    "            TuningParam(1, \"avgpool\", None),\n",
    "            TuningParam(1, \"features\", self._inclusive_range(28, 34)),\n",
    "            TuningParam(2, \"features\", self._inclusive_range(21, 27)),\n",
    "            TuningParam(3, \"features\", self._inclusive_range(14, 20)),\n",
    "            TuningParam(4, \"features\", self._inclusive_range(7, 13)),\n",
    "            TuningParam(5, \"features\", self._inclusive_range(0, 6))\n",
    "        ]\n",
    "\n",
    "        self._freeze_layers(tuning_params, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rvNj4Qb421UH"
   },
   "outputs": [],
   "source": [
    "class VGG16BN(VGGBase):\n",
    "    \"\"\"\n",
    "    VGG16BN model that may be pretrained and fine tuned. The tuning_level\n",
    "    parameter controls the degree of fine tuning as depicted in the table\n",
    "    below.\n",
    "    \n",
    "        VGG16_BN            tuning_level\n",
    "        ----------------    ------------\n",
    "        features\n",
    "          [00-02] CNR           >= 5\n",
    "          [03-05] CNR           >= 5\n",
    "          [06] MaxPool2d        >= 5\n",
    "          [07-09] CNR           >= 4\n",
    "          [10-12] CNR           >= 4\n",
    "          [13] MaxPool2d        >= 4\n",
    "          [14-16] CNR           >= 3\n",
    "          [17-19] CNR           >= 3\n",
    "          [20-22] CNR           >= 3\n",
    "          [23] MaxPool2d        >= 3\n",
    "          [24-26] CNR           >= 2\n",
    "          [27-29] CNR           >= 2\n",
    "          [30-32] CNR           >= 2\n",
    "          [33] MaxPool2d        >= 2\n",
    "          [34-36] CNR           >= 1\n",
    "          [37-39] CNR           >= 1\n",
    "          [40-42] CNR           >= 1\n",
    "          [43] MaxPool2d        >= 1\n",
    "        avgpool                 >= 1\n",
    "        classifier              \n",
    "          [00-02] LRD           >= 0\n",
    "          [03-05] LRD           >= 0\n",
    "          [06] Linear           >= 0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.vgg16_bn, pretrained)\n",
    "            \n",
    "        # ToDo: Omit layer types that do not have trainable parameters\n",
    "        tuning_params = [\n",
    "            TuningParam(0, \"classifier\", None),\n",
    "            TuningParam(1, \"avgpool\", None),\n",
    "            TuningParam(1, \"features\", self._inclusive_range(34, 43)),\n",
    "            TuningParam(2, \"features\", self._inclusive_range(24, 33)),\n",
    "            TuningParam(3, \"features\", self._inclusive_range(14, 23)),\n",
    "            TuningParam(4, \"features\", self._inclusive_range(7, 13)),\n",
    "            TuningParam(5, \"features\", self._inclusive_range(0, 6))\n",
    "        ]\n",
    "\n",
    "        self._freeze_layers(tuning_params, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckZqYccc21c3"
   },
   "outputs": [],
   "source": [
    "class VGG19BN(VGGBase):\n",
    "    \"\"\"\n",
    "    VGG19BN model that may be pretrained and fine tuned. The tuning_level\n",
    "    parameter controls the degree of fine tuning as depicted in the table\n",
    "    below.\n",
    "\n",
    "        VGG11_BN            tuning_level\n",
    "        ----------------    ------------\n",
    "        features\n",
    "          [00-02] CNR           >= 5\n",
    "          [03-05] CNR           >= 5\n",
    "          [06] MaxPool2d        >= 5\n",
    "          [07-09] CNR           >= 4\n",
    "          [10-12] CNR           >= 4\n",
    "          [13] MaxPool2d        >= 4\n",
    "          [14-16] CNR           >= 3\n",
    "          [17-19] CNR           >= 3\n",
    "          [20-22] CNR           >= 3\n",
    "          [23-25] CNR           >= 3\n",
    "          [26] MaxPool2d        >= 3\n",
    "          [27-29] CNR           >= 2\n",
    "          [30-32] CNR           >= 2\n",
    "          [33-35] CNR           >= 2\n",
    "          [36-38] CNR           >= 2\n",
    "          [39] MaxPool2d        >= 2\n",
    "          [40-42] CNR           >= 1\n",
    "          [43-45] CNR           >= 1\n",
    "          [46-48] CNR           >= 1\n",
    "          [49-51] CNR           >= 1\n",
    "          [52] MaxPool2d        >= 1\n",
    "        avgpool                 >= 1\n",
    "        classifier              \n",
    "          [00-02] LRD           >= 0\n",
    "          [03-05] LRD           >= 0\n",
    "          [06] Linear           >= 0\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.vgg19_bn, pretrained)\n",
    "            \n",
    "        # ToDo: Omit layer types that do not have trainable parameters\n",
    "        tuning_params = [\n",
    "            TuningParam(0, \"classifier\", None),\n",
    "            TuningParam(1, \"avgpool\", None),\n",
    "            TuningParam(1, \"features\", self._inclusive_range(40, 52)),\n",
    "            TuningParam(2, \"features\", self._inclusive_range(27, 39)),\n",
    "            TuningParam(3, \"features\", self._inclusive_range(14, 26)),\n",
    "            TuningParam(4, \"features\", self._inclusive_range(7, 13)),\n",
    "            TuningParam(5, \"features\", self._inclusive_range(0, 6))\n",
    "        ]\n",
    "\n",
    "        self._freeze_layers(tuning_params, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DonDtN5MBBU1"
   },
   "outputs": [],
   "source": [
    "class DenseNetBase(TorchVisionModel):\n",
    "    \"\"\"\n",
    "    Base class for DenseNet models that may be pretrained and fine tuned. The\n",
    "    tuning_level parameter controls the degree of fine tuning as depicted in\n",
    "    the table below.\n",
    "        \n",
    "        DenseNet          tuning_level\n",
    "        -------------     ------------\n",
    "        features\n",
    "          conv0               >= 5\n",
    "          norm0               >= 5\n",
    "          relu0               >= 5\n",
    "          pool0               >= 5\n",
    "          denseblock1         >= 4\n",
    "          transition1         >= 4\n",
    "          denseblock2         >= 3\n",
    "          transition2         >= 3\n",
    "          denseblock3         >= 2\n",
    "          transition3         >= 2\n",
    "          denseblock4         >= 1\n",
    "          norm5               >= 1\n",
    "        classifier            >= 0\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_fn: Callable, pretrained=True, tuning_level=0):\n",
    "        super().__init__(model_fn(pretrained=pretrained))\n",
    "\n",
    "        # change the output layer\n",
    "        last_layer_in = self._network.classifier.in_features\n",
    "        self._network.classifier = nn.Linear(last_layer_in, 13)\n",
    "\n",
    "        # ToDo: Omit layer types that do not have trainable parameters\n",
    "        tuning_params = [\n",
    "            TuningParam(0, \"classifier\", None),\n",
    "            TuningParam(1, \"features\", [\"denseblock4\", \"norm5\"]),\n",
    "            TuningParam(2, \"features\", [\"denseblock3\", \"transition3\"]),\n",
    "            TuningParam(3, \"features\", [\"denseblock2\", \"transition2\"]),\n",
    "            TuningParam(4, \"features\", [\"denseblock1\", \"transition1\"]),\n",
    "            TuningParam(5, \"features\", [\"conv0\", \"norm0\", \"relu0\", \"pool0\"])\n",
    "        ]\n",
    "\n",
    "        self._freeze_layers(tuning_params, pretrained, tuning_level)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self._network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckZqYccc21c3"
   },
   "outputs": [],
   "source": [
    "class DenseNet121(DenseNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.densenet121, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckZqYccc21c3"
   },
   "outputs": [],
   "source": [
    "class DenseNet169(DenseNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.densenet169, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ckZqYccc21c3"
   },
   "outputs": [],
   "source": [
    "class DenseNet201(DenseNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.densenet201, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet161(DenseNetBase):\n",
    "    def __init__(self, pretrained=True, tuning_level=0):\n",
    "        super().__init__(models.densenet161, pretrained, tuning_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHRk6r0s3-51"
   },
   "outputs": [],
   "source": [
    "class Project1Model(nn.Module):\n",
    "    \"\"\"\n",
    "    Modified the last layer to output 13, rather than 3, features.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            # input 3 x 224 x 224\n",
    "            nn.Conv2d(in_channels=3, out_channels=16, kernel_size=7, padding=3),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            # input 24 * 112 * 112\n",
    "            nn.Conv2d(in_channels=16, out_channels=24, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(24),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            # input 36 * 56 * 56\n",
    "            nn.Conv2d(in_channels=24, out_channels=36, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(36),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            #input 54 * 28 * 28\n",
    "            nn.Conv2d(in_channels=36, out_channels=54, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(54),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            #input 81 * 14 * 14\n",
    "            nn.Conv2d(in_channels=54, out_channels=81, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(81),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=81*7*7, out_features=1024), \n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=1024, out_features=256), \n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Linear(in_features=256, out_features=13)            \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self._body(x)\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self._head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5XjG813k3-52"
   },
   "source": [
    "## <font style=\"color:green\">6. Utils [5 Points]</font>\n",
    "\n",
    "Define your methods or classes which are not covered in the above sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(cm, classes, model_name=None):\n",
    "    \"\"\"\n",
    "    Creates and returns a confusion matrix figure that can be saved to a file or .\n",
    "    \"\"\"\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "    # compute accuracy, normalized confusion matrix\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    cm_norm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # initialize the plot tick marks and title\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    title = \"Confusion Matrix\"\n",
    "    if model_name is not None:\n",
    "        title = title + \" ({})\".format(model_name)\n",
    "    \n",
    "    # plot the confusion matrix\n",
    "    plt.style.use('default')\n",
    "    fig = plt.figure(figsize=(11,10), tight_layout=True)\n",
    "    im = plt.imshow(cm_norm, interpolation=\"nearest\", cmap=plt.cm.Blues, vmin=0., vmax=1.)\n",
    "\n",
    "    plt.title(title + \"\\n\")\n",
    "    plt.xticks(tick_marks, classes, rotation=22.5)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(\n",
    "            j, i,\n",
    "            format(cm[i, j], \"d\") + \"\\n\" + format(cm_norm[i, j], \".2f\"), \n",
    "            horizontalalignment=\"center\",\n",
    "            verticalalignment=\"center\",\n",
    "            color=\"white\" if cm_norm[i, j] > 0.5 else \"black\"\n",
    "        )\n",
    "\n",
    "    plt.ylabel(\"Target Labels\")\n",
    "    plt.xlabel(\"Predicted Labels\\nAccuracy={:0.4f}\".format(accuracy))\n",
    "    \n",
    "    # plot the color bar\n",
    "    divider = make_axes_locatable(plt.gca())\n",
    "    cax = divider.append_axes(\"right\", size=0.3, pad=0.2)\n",
    "    plt.colorbar(im, cax=cax)\n",
    "\n",
    "    # close the plot and return the figure\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_requires_grad_status(block) -> str:\n",
    "    params = list(block.parameters())\n",
    "    if not params:\n",
    "        return \"N/A\"\n",
    "    \n",
    "    or_of_params = False\n",
    "    and_of_params = True\n",
    "    for param in params:\n",
    "        or_of_params = or_of_params or param.requires_grad\n",
    "        and_of_params = and_of_params and param.requires_grad\n",
    "    if or_of_params and and_of_params:\n",
    "        return \"True\"\n",
    "    elif not or_of_params and not and_of_params:\n",
    "        return \"False\"\n",
    "    else:\n",
    "        return \"Mixed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top_level_model_blocks(\n",
    "    model:nn.Module, \n",
    "    include_grandchildren:bool = False, \n",
    "    display_requires_grad = False\n",
    "):\n",
    "    status = \"\"\n",
    "    if display_requires_grad:\n",
    "        status = f\", requires_grad={get_requires_grad_status(model)}\"\n",
    "    print(f\"{type(model).__name__}{status}\")\n",
    "    for child in model.named_children():\n",
    "        if display_requires_grad:\n",
    "            status = f\", requires_grad={get_requires_grad_status(child[1])}\"\n",
    "        print(f\"  {child[0]}{status}\")\n",
    "        if include_grandchildren:\n",
    "            for grandchild in child[1].named_children():\n",
    "                if display_requires_grad:\n",
    "                    status = f\", requires_grad={get_requires_grad_status(grandchild[1])}\"\n",
    "                if not grandchild[0].isnumeric():\n",
    "                    print(f\"    { grandchild[0]}{status}\")\n",
    "                else:\n",
    "                    print(f\"    [{grandchild[0]}] {type(grandchild[1]).__name__}{status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Output the architecture of several pretrained PyTorch models.\n",
    "#  \n",
    "#  The following models all have the same high level ResNet architecture.\n",
    "#  \n",
    "#      - ResNet-18\n",
    "#      - ResNet-34\n",
    "#      - ResNet-50\n",
    "#      - ResNet-101\n",
    "#      - ResNet-152\n",
    "#      - ResNeXt-50-32x4d\n",
    "#      - Wide ResNet-50-2\n",
    "#      - Wide ResNet-101-2\n",
    "#  \n",
    "#  The following models all have the same high level DenseNet architecture.\n",
    "#  \n",
    "#      - Densenet-121\n",
    "#      - Densenet-169\n",
    "#      - Densenet-201\n",
    "#      - Densenet-161\n",
    "\n",
    "\n",
    "#  print_top_level_model_blocks(models.resnet18(), False)\n",
    "#  print_top_level_model_blocks(models.densenet121(), True)\n",
    "#  print_top_level_model_blocks(models.vgg11_bn(), True)\n",
    "#  print_top_level_model_blocks(models.vgg13_bn(), True)\n",
    "#  print_top_level_model_blocks(models.vgg16_bn(), True)\n",
    "#  print_top_level_model_blocks(models.vgg19_bn(), True)\n",
    "\n",
    "\n",
    "#  The (formatted) output the previous commented statements yields the following.\n",
    "#  \n",
    "#  Note: Groups of Conv2d, BatchNorm, and ReLU layers have been condensed to CNR\n",
    "#        Groups of Linear, ReLU, and Dropout layers have been condensed to LRD\n",
    "#  \n",
    "#  ResNet           | DenseNet         | VGG11_BN         | VGG13_BN         | VGG16_BN         | VGG19_BN\n",
    "#    conv1          |   features       |   features       |   features       |   features       |   features\n",
    "#    bn1            |     conv0        |     [00-02] CNR  |     [00-02] CNR  |     [00-02] CNR  |     [00-02] CNR\n",
    "#    relu           |     norm0        |                  |     [03-05] CNR  |     [03-05] CNR  |     [03-05] CNR\n",
    "#    maxpool        |     relu0        |     [03] MaxPool |     [06] MaxPool |     [06] MaxPool |     [06] MaxPool2d\n",
    "#    layer1         |     pool0        |     [04-06] CNR  |     [07-09] CNR  |     [07-09] CNR  |     [07-09] CNR\n",
    "#    layer2         |     denseblock1  |                  |     [10-12] CNR  |     [10-12] CNR  |     [10-12] CNR\n",
    "#    layer3         |     transition1  |     [07] MaxPool |     [13] MaxPool |     [13] MaxPool |     [13] MaxPool2d\n",
    "#    layer4         |     denseblock2  |     [08-10] CNR  |     [14-16] CNR  |     [14-16] CNR  |     [14-16] CNR\n",
    "#    avgpool        |     transition2  |     [11-13] CNR  |     [17-19] CNR  |     [17-19] CNR  |     [17-19] CNR\n",
    "#    fc             |     denseblock3  |                  |                  |     [20-22] CNR  |     [20-22] CNR\n",
    "#                   |     transition3  |                  |                  |                  |     [23-25] CNR\n",
    "#                   |     denseblock4  |     [14] MaxPool |     [20] MaxPool |     [23] MaxPool |     [26] MaxPool2d\n",
    "#                   |     norm5        |     [15-17] CNR  |     [21-23] CNR  |     [24-26] CNR  |     [27-29] CNR\n",
    "#                   |   classifier     |     [18-20] CNR  |     [24-26] CNR  |     [27-29] CNR  |     [30-32] CNR\n",
    "#                   |                  |                  |                  |     [30-32] CNR  |     [33-35] CNR\n",
    "#                   |                  |                  |                  |                  |     [36-38] CNR\n",
    "#                   |                  |     [21] MaxPool |     [27] MaxPool |     [33] MaxPool |     [39] MaxPool2d\n",
    "#                   |                  |     [22-24] CNR  |     [28-30] CNR  |     [34-36] CNR  |     [40-42] CNR\n",
    "#                   |                  |     [25-27] CNR  |     [31-33] CNR  |     [37-39] CNR  |     [43-45] CNR\n",
    "#                   |                  |                  |                  |     [40-42] CNR  |     [46-48] CNR\n",
    "#                   |                  |                  |                  |                  |     [49-51] CNR\n",
    "#                   |                  |     [28] MaxPool |     [34] MaxPool |     [43] MaxPool |     [52] MaxPool2d\n",
    "#                   |                  |   avgpool        |   avgpool        |   avgpool        |   avgpool\n",
    "#                   |                  |   classifier     |   classifier     |   classifier     |   classifier\n",
    "#                   |                  |     [00-02] LRD  |     [00-02] LRD  |     [00-02] LRD  |     [00-02] LRD\n",
    "#                   |                  |     [03-05] LRD  |     [03-05] LRD  |     [03-05] LRD  |     [03-05] LRD\n",
    "#                   |                  |     [06] Linear  |     [06] Linear  |     [06] Linear  |     [06] Linear\n",
    "\n",
    "\n",
    "#  This function was also used to test whether I properly implemented the fine tuning code. For example,\n",
    "#\n",
    "#  model = ResNet18(pretrained=True, tuning_level=0)\n",
    "#  print_top_level_model_blocks(model._network, include_grandchildren=False, display_requires_grad=True)\n",
    "#\n",
    "#      ResNet, requires_grad=Mixed\n",
    "#        conv1, requires_grad=False\n",
    "#        bn1, requires_grad=False\n",
    "#        relu, requires_grad=N/A\n",
    "#        maxpool, requires_grad=N/A\n",
    "#        layer1, requires_grad=False\n",
    "#        layer2, requires_grad=False\n",
    "#        layer3, requires_grad=False\n",
    "#        layer4, requires_grad=False\n",
    "#        avgpool, requires_grad=N/A\n",
    "#        fc, requires_grad=True#\n",
    "#\n",
    "#  model = ResNet18(pretrained=True, tuning_level=1)\n",
    "#  print_top_level_model_blocks(model._network, include_grandchildren=False, display_requires_grad=True)\n",
    "#\n",
    "#      ResNet, requires_grad=Mixed\n",
    "#        conv1, requires_grad=False\n",
    "#        bn1, requires_grad=False\n",
    "#        relu, requires_grad=N/A\n",
    "#        maxpool, requires_grad=N/A\n",
    "#        layer1, requires_grad=False\n",
    "#        layer2, requires_grad=False\n",
    "#        layer3, requires_grad=False\n",
    "#        layer4, requires_grad=True\n",
    "#        avgpool, requires_grad=N/A\n",
    "#        fc, requires_grad=True\n",
    "#\n",
    "#  ...\n",
    "#\n",
    "#  model = ResNet18(pretrained=True, tuning_level=5)\n",
    "#  print_top_level_model_blocks(model._network, include_grandchildren=False, display_requires_grad=True)\n",
    "#\n",
    "#      ResNet, requires_grad=True\n",
    "#        conv1, requires_grad=True\n",
    "#        bn1, requires_grad=True\n",
    "#        relu, requires_grad=N/A\n",
    "#        maxpool, requires_grad=N/A\n",
    "#        layer1, requires_grad=True\n",
    "#        layer2, requires_grad=True\n",
    "#        layer3, requires_grad=True\n",
    "#        layer4, requires_grad=True\n",
    "#        avgpool, requires_grad=N/A\n",
    "#        fc, requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sxmMNijlAb9v"
   },
   "outputs": [],
   "source": [
    "def creeate_submission_csv(path, exp):\n",
    "    \"\"\"\n",
    "    ToDo: Need to test and execute on the best model.\n",
    "    \"\"\"\n",
    "\n",
    "    # create a dictionary of numeric labels to text labels\n",
    "    label_dict = {}\n",
    "    for key, value in zip(np.arange(len(exp.classes)), exp.classes):\n",
    "        label_dict[key] = value\n",
    "\n",
    "    # get predictions for the test data using the trained model            \n",
    "    fnames, labels = predict_test_data(exp.trained_model, exp.test_loader, exp.device)\n",
    "\n",
    "    # convert the numeric labels to their text equivalents\n",
    "    labels = [label_dict[label] for label in labels]\n",
    "\n",
    "    # create a pandas data frame and write it to a CSV file\n",
    "    data_frame = pd.DataFrame(\n",
    "        np.stack((fnames, labels), axis=-1), \n",
    "        columns=[\"id\", \"class\"]\n",
    "    )\n",
    "\n",
    "    data_frame.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssjl7-QG3-52"
   },
   "source": [
    "## <font style=\"color:green\">7. Experiment [5 Points]</font>\n",
    "\n",
    "Choose your optimizer and LR-scheduler and use the above methods and classes to train your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "exu5ZBHV-U-G"
   },
   "source": [
    "### <font style=\"color:blue\">Base Experiment Classes</font>\n",
    "\n",
    "The following base classes facilitate experiment creation.\n",
    "<ul>\n",
    "    <li>Experiment - Base class for the following classes.</li>\n",
    "    <li>VisualExperiment - Conduct data visualization experiments.</li>\n",
    "    <li>ModelExperiment - Conduct model training experiments</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hQXZGHy0CzTZ"
   },
   "outputs": [],
   "source": [
    "class Experiment(ABC):\n",
    "    def __init__(\n",
    "        self,\n",
    "        abbr: str = None,\n",
    "        transform_resize: int = 256,\n",
    "        transform_crop_size: int = 224,\n",
    "        data_aug_color_enabled: bool = None,\n",
    "        data_aug_color_brightness: Tuple[float, float] = None,\n",
    "        data_aug_color_contrast: Tuple[float, float] = None,\n",
    "        data_aug_color_saturation: Tuple[float, float] = None,\n",
    "        data_aug_color_hue: Tuple[float, float] = None,\n",
    "        data_aug_horz_flip_prob: float = None,\n",
    "        data_aug_vert_flip_prob: float = None,\n",
    "        data_aug_affine_enabled: bool = None,\n",
    "        data_aug_affine_rotation: float = None,\n",
    "        data_aug_affine_translate: Tuple[float, float] = None,\n",
    "        data_aug_affine_scale: Tuple[float, float] = None,\n",
    "        data_aug_erasing_prob: float = None,\n",
    "        data_aug_erasing_scale: Tuple[float, float] = None,\n",
    "        data_aug_erasing_ratio: Tuple[float, float] = None,\n",
    "        data_loader_batch_size: int = None,\n",
    "        data_loader_num_workers: int = None,\n",
    "        optimzer_learning_rate: float = None,\n",
    "        optimzer_momentum: float = None,\n",
    "        optimzer_weight_decay: float = None,\n",
    "        optimzer_betas: Tuple[float, float] = None,\n",
    "        lr_scheduler_gamma: float = None,\n",
    "        lr_scheduler_step_size: int = None,\n",
    "        lr_scheduler_milestones: Iterable = None,\n",
    "        lr_scheduler_patience: int = None,\n",
    "        lr_scheduler_threshold: float = None,\n",
    "        trainer_training_epochs: int = None,\n",
    "        trainer_stop_loss_epochs: int = None,\n",
    "        trainer_stop_acc_epochs: int = None,\n",
    "        trainer_stop_acc_ema_alpha: float = None,\n",
    "        trainer_stop_acc_threshold: float = None\n",
    "    ):\n",
    "\n",
    "        \"\"\"\n",
    "        This base class for data visualization and model training experiment does the following.\n",
    "        \n",
    "            - Creates the master configuration instance accomodating constructor overrides\n",
    "            - Sets up the system, e.g., ensures reproducibility, enables CUDA acceleration, etc.\n",
    "            - Initializes the KenyanFood13 dataset\n",
    "            - Configures experiment visualization \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if abbr is None:\n",
    "            self._abbr = type(self).__name__\n",
    "        else:\n",
    "            self._abbr = abbr\n",
    "\n",
    "        \n",
    "        # ToDo: Apply patch if CUDA is not available.\n",
    "        self._resize = transform_resize\n",
    "        self._crop_size = transform_crop_size\n",
    "        self._config = create_master_config(\n",
    "            transform_resize,\n",
    "            transform_crop_size,\n",
    "            data_aug_color_enabled,\n",
    "            data_aug_color_brightness,\n",
    "            data_aug_color_contrast,\n",
    "            data_aug_color_saturation,\n",
    "            data_aug_color_hue,\n",
    "            data_aug_horz_flip_prob,\n",
    "            data_aug_vert_flip_prob,\n",
    "            data_aug_affine_enabled,\n",
    "            data_aug_affine_rotation,\n",
    "            data_aug_affine_translate,\n",
    "            data_aug_affine_scale,\n",
    "            data_aug_erasing_prob,\n",
    "            data_aug_erasing_scale,\n",
    "            data_aug_erasing_ratio,\n",
    "            data_loader_batch_size,\n",
    "            data_loader_num_workers,\n",
    "            optimzer_learning_rate,\n",
    "            optimzer_momentum,\n",
    "            optimzer_weight_decay,\n",
    "            optimzer_betas,\n",
    "            lr_scheduler_gamma,\n",
    "            lr_scheduler_step_size,\n",
    "            lr_scheduler_milestones,\n",
    "            lr_scheduler_patience,\n",
    "            lr_scheduler_threshold,  \n",
    "            trainer_training_epochs,\n",
    "            trainer_stop_loss_epochs,\n",
    "            trainer_stop_acc_epochs,\n",
    "            trainer_stop_acc_ema_alpha,\n",
    "            trainer_stop_acc_threshold       \n",
    "        )\n",
    "        \n",
    "\n",
    "        setup_system(self._config.system)\n",
    "        \n",
    "        self._data = KenyanFood13Data(\n",
    "            data_root = self._config.dataset.data_dir,\n",
    "            valid_size = self._config.dataset.valid_size,\n",
    "            random_seed = self._config.system.seed\n",
    "        )\n",
    "\n",
    "        self._classes = self._data.classes\n",
    "        self._library = self._data.library\n",
    "        self.__visualizer = None\n",
    "        \n",
    "    @property\n",
    "    def classes(self):\n",
    "        return self._classes\n",
    "\n",
    "    @property\n",
    "    def library(self):\n",
    "        return self._library\n",
    "\n",
    "    \"\"\"\n",
    "    Protected methods that may or must be overridden by derived classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractproperty\n",
    "    def _visualizer_name(self) -> str:\n",
    "        pass\n",
    "\n",
    "    def _open_visualizer(self):\n",
    "        if self.__visualizer is None:\n",
    "            self.__visualizer = TensorBoardVisualizer(os.path.join(\n",
    "                self._config.system.proj_dir,\n",
    "                self._config.trainer.visualizer_dir, \n",
    "                self._visualizer_name\n",
    "            ))\n",
    "        return self.__visualizer\n",
    "\n",
    "    def _close_visualizer(self):\n",
    "        if self.__visualizer is not None:\n",
    "            self.__visualizer.close_tensorboard()\n",
    "            self.__visualizer = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SL2_K0Br-U-G"
   },
   "outputs": [],
   "source": [
    "class VisualExperiment(Experiment):\n",
    "    def __init__(\n",
    "        self,\n",
    "        abbr: str = None,\n",
    "        transform_resize: int = 256,\n",
    "        transform_crop_size: int = 224,\n",
    "        data_aug_color_enabled: bool = None,\n",
    "        data_aug_color_brightness: Tuple[float, float] = None,\n",
    "        data_aug_color_contrast: Tuple[float, float] = None,\n",
    "        data_aug_color_saturation: Tuple[float, float] = None,\n",
    "        data_aug_color_hue: Tuple[float, float] = None,\n",
    "        data_aug_horz_flip_prob: float = None,\n",
    "        data_aug_vert_flip_prob: float = None,\n",
    "        data_aug_affine_enabled: bool = None,\n",
    "        data_aug_affine_rotation: float = None,\n",
    "        data_aug_affine_translate: Tuple[float, float] = None,\n",
    "        data_aug_affine_scale: Tuple[float, float] = None,\n",
    "        data_aug_erasing_prob: float = None,\n",
    "        data_aug_erasing_scale: Tuple[float, float] = None,\n",
    "        data_aug_erasing_ratio: Tuple[float, float] = None\n",
    "    ):\n",
    "        super().__init__(\n",
    "            abbr,\n",
    "            transform_resize,\n",
    "            transform_crop_size,\n",
    "            data_aug_color_enabled,\n",
    "            data_aug_color_brightness,\n",
    "            data_aug_color_contrast,\n",
    "            data_aug_color_saturation,\n",
    "            data_aug_color_hue,\n",
    "            data_aug_horz_flip_prob,\n",
    "            data_aug_vert_flip_prob,\n",
    "            data_aug_affine_enabled,\n",
    "            data_aug_affine_rotation,\n",
    "            data_aug_affine_translate,\n",
    "            data_aug_affine_scale,\n",
    "            data_aug_erasing_prob,\n",
    "            data_aug_erasing_scale,\n",
    "            data_aug_erasing_ratio\n",
    "        )\n",
    "        \n",
    "        \"\"\"\n",
    "        This is the base class for data visualization experiments.\n",
    "        \"\"\"\n",
    "\n",
    "    def log_sample_images(self):\n",
    "        \"\"\"\n",
    "        Create a 6 x 6 grid of images for each type of food in the data and\n",
    "        log these images to the visualizer.\n",
    "        \"\"\"\n",
    "\n",
    "        visualizer = self._open_visualizer()\n",
    "\n",
    "        for food, fnames in self._library.items():\n",
    "            # create food specific dataset\n",
    "            dataset = KenyanFood13Dataset(\n",
    "                image_root=self._data.image_root,\n",
    "                fnames=fnames,\n",
    "                transform=self._config.dataset.visual_transforms\n",
    "            )\n",
    "\n",
    "            # randomly load 36 images\n",
    "            dataloader = DataLoader(dataset, batch_size=36, shuffle=True)\n",
    "            images, _ = next(iter(dataloader))\n",
    "\n",
    "            # save image to project directory\n",
    "            # path = os.path.join(proj_dir, self._classes[food] + \".jpg\")\n",
    "            # torchvision.utils.save_image(images, fp=path, nrow=6)\n",
    "\n",
    "            # add image grid to visualizer\n",
    "            visualizer.add_image(\n",
    "                tag=self._classes[food], \n",
    "                image=torchvision.utils.make_grid(images, nrow=6)\n",
    "            )\n",
    "        \n",
    "        self._close_visualizer()\n",
    "        \n",
    "    @property\n",
    "    def _visualizer_name(self) -> str:\n",
    "        return self._abbr + f\"--DV-RS_{self._resize}-CS_{self._crop_size}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dmU0Q8Ek3-52"
   },
   "outputs": [],
   "source": [
    "class ModelExperiment(Experiment):\n",
    "    def __init__(\n",
    "        self,\n",
    "        abbr: str = None,\n",
    "        data_augmentation: bool = True,\n",
    "        optimizer: Optimizer = Optimizer.SGD,\n",
    "        lr_scheduler: LrScheduler = LrScheduler.STEP,\n",
    "        transform_resize: int = 256,\n",
    "        transform_crop_size: int = 224,\n",
    "        data_aug_color_enabled: bool = None,\n",
    "        data_aug_color_brightness: Tuple[float, float] = None,\n",
    "        data_aug_color_contrast: Tuple[float, float] = None,\n",
    "        data_aug_color_saturation: Tuple[float, float] = None,\n",
    "        data_aug_color_hue: Tuple[float, float] = None,\n",
    "        data_aug_horz_flip_prob: float = None,\n",
    "        data_aug_vert_flip_prob: float = None,\n",
    "        data_aug_affine_enabled: bool = None,\n",
    "        data_aug_affine_rotation: float = None,\n",
    "        data_aug_affine_translate: Tuple[float, float] = None,\n",
    "        data_aug_affine_scale: Tuple[float, float] = None,\n",
    "        data_aug_erasing_prob: float = None,\n",
    "        data_aug_erasing_scale: Tuple[float, float] = None,\n",
    "        data_aug_erasing_ratio: Tuple[float, float] = None,\n",
    "        data_loader_batch_size: int = None,\n",
    "        data_loader_num_workers: int = None,\n",
    "        optimzer_learning_rate: float = None,\n",
    "        optimzer_momentum: float = None,\n",
    "        optimzer_weight_decay: float = None,\n",
    "        optimzer_betas: Tuple[float, float] = None,\n",
    "        lr_scheduler_gamma: float = None,\n",
    "        lr_scheduler_step_size: int = None,\n",
    "        lr_scheduler_milestones: Iterable = None,\n",
    "        lr_scheduler_patience: int = None,\n",
    "        lr_scheduler_threshold: float = None,\n",
    "        trainer_training_epochs: int = None,\n",
    "        trainer_stop_loss_epochs: int = None,\n",
    "        trainer_stop_acc_epochs: int = None,\n",
    "        trainer_stop_acc_ema_alpha: float = None,\n",
    "        trainer_stop_acc_threshold: float = None,\n",
    "        use_data_subsets: bool = False\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This is the base class for model training experiments.\n",
    "        \"\"\"\n",
    "        \n",
    "        super().__init__(\n",
    "            abbr,\n",
    "            transform_resize,\n",
    "            transform_crop_size,\n",
    "            data_aug_color_enabled,\n",
    "            data_aug_color_brightness,\n",
    "            data_aug_color_contrast,\n",
    "            data_aug_color_saturation,\n",
    "            data_aug_color_hue,\n",
    "            data_aug_horz_flip_prob,\n",
    "            data_aug_vert_flip_prob,\n",
    "            data_aug_affine_enabled,\n",
    "            data_aug_affine_rotation,\n",
    "            data_aug_affine_translate,\n",
    "            data_aug_affine_scale,\n",
    "            data_aug_erasing_prob,\n",
    "            data_aug_erasing_scale,\n",
    "            data_aug_erasing_ratio,\n",
    "            data_loader_batch_size,\n",
    "            data_loader_num_workers,\n",
    "            optimzer_learning_rate,\n",
    "            optimzer_momentum,\n",
    "            optimzer_weight_decay,\n",
    "            optimzer_betas,\n",
    "            lr_scheduler_gamma,\n",
    "            lr_scheduler_step_size,\n",
    "            lr_scheduler_milestones,\n",
    "            lr_scheduler_patience,\n",
    "            lr_scheduler_threshold,\n",
    "            trainer_training_epochs,\n",
    "            trainer_stop_loss_epochs,\n",
    "            trainer_stop_acc_epochs,\n",
    "            trainer_stop_acc_ema_alpha,\n",
    "            trainer_stop_acc_threshold\n",
    "        )\n",
    "\n",
    "        test_transforms = self._config.dataset.test_transforms\n",
    "        train_transforms = self._config.dataset.train_transforms\n",
    "        if not data_augmentation:\n",
    "            train_transforms = test_transforms\n",
    "\n",
    "        train_dataset, valid_dataset, test_dataset = get_datasets(\n",
    "            data = self._data,\n",
    "            test_transforms = test_transforms,\n",
    "            train_transforms = train_transforms,\n",
    "            subset = use_data_subsets\n",
    "        )\n",
    "\n",
    "        self.__train_loader, self.__valid_loader, self.__test_loader = get_data_loaders(\n",
    "            train_dataset = train_dataset,\n",
    "            valid_dataset = valid_dataset,\n",
    "            test_dataset = test_dataset,\n",
    "            batch_size = self._config.data_loader.batch_size,\n",
    "            num_workers = self._config.data_loader.num_workers\n",
    "        )                \n",
    "    \n",
    "        self.__model, model_id = self._get_model()\n",
    "        self.__model_name = self._abbr + \"--\" + model_id\n",
    "        self.__model_dir = os.path.join(self._config.system.proj_dir, self._config.trainer.model_dir)\n",
    "        self.__loss_fn = weighted_cross_entropy_loss\n",
    "        self.__metric_fn = AccuracyEstimator(topk=(1, )) # ToDo: Fix! (trainer.py expects a dictionary w/ 'top1' key)\n",
    "        self.__optimizer = get_optimizer(self.__model, optimizer, self._config.optimizer)\n",
    "        self.__lr_scheduler = get_lr_scheduler(self.__optimizer, lr_scheduler, self._config.scheduler)\n",
    "\n",
    "    @property\n",
    "    def test_loader(self) -> DataLoader:\n",
    "        return self.__test_loader\n",
    "\n",
    "    @property\n",
    "    def train_loader(self):\n",
    "        return self.__train_loader\n",
    "    \n",
    "    @property\n",
    "    def valid_loader(self):\n",
    "        return self.__valid_loader\n",
    "\n",
    "    @property\n",
    "    def device(self) -> torch.device:\n",
    "        return torch.device(self._config.trainer.device)\n",
    "\n",
    "    @property\n",
    "    def trained_model_path(self):\n",
    "        return os.path.join(self.__model_dir, self.__model_name + \".pt\")\n",
    "    \n",
    "    @property\n",
    "    def trained_model(self) -> nn.Module:\n",
    "        self.__load_model()\n",
    "        return self.__model\n",
    "\n",
    "    def train(self):\n",
    "        device = self.device\n",
    "        self.__model = self.__model.to(device)\n",
    "        self.__loss_fn = self.__loss_fn.to(device)\n",
    "\n",
    "        visualizer = self._open_visualizer()\n",
    "        model_trainer = Trainer(\n",
    "            model=self.__model,\n",
    "            loader_train=self.__train_loader,\n",
    "            loader_test=self.__valid_loader,\n",
    "            loss_fn=self.__loss_fn,\n",
    "            metric_fn=self.__metric_fn,\n",
    "            optimizer=self.__optimizer,\n",
    "            lr_scheduler=self.__lr_scheduler,\n",
    "            model_save_dir=self.__model_dir,\n",
    "            model_name=self.__model_name,\n",
    "            model_saving_period=0,\n",
    "            stop_loss_epochs=self._config.trainer.stop_loss_epochs,\n",
    "            stop_acc_ema_alpha=self._config.trainer.stop_acc_ema_alpha,\n",
    "            stop_acc_epochs=self._config.trainer.stop_acc_epochs,\n",
    "            stop_acc_threshold=self._config.trainer.stop_acc_threshold,\n",
    "            device=device,\n",
    "            data_getter=itemgetter(0),\n",
    "            target_getter=itemgetter(1),\n",
    "            stage_progress=self._config.trainer.progress_bar,\n",
    "            visualizer=visualizer,\n",
    "            get_key_metric=itemgetter(\"top1\")\n",
    "        )\n",
    "        model_trainer.register_hook(\"end_epoch\", hooks.end_epoch_hook_classification)\n",
    "        metrics = model_trainer.fit(self._config.trainer.training_epochs)\n",
    "        self._close_visualizer()\n",
    "\n",
    "        return metrics\n",
    "    \n",
    "    def log_graph(self):\n",
    "        model = self.trained_model\n",
    "        images, _ = next(iter(self.valid_loader))\n",
    "        device = self.device\n",
    "\n",
    "        visualizer = self._open_visualizer()\n",
    "        visualizer.add_graph(model.to(device), images.to(device))\n",
    "        self._close_visualizer()\n",
    "        \n",
    "    \n",
    "    def log_pr_curves(self):\n",
    "        targets, pred_probs = get_targets_and_pred_probs(\n",
    "            self.trained_model, \n",
    "            self.valid_loader,\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        visualizer = self._open_visualizer()\n",
    "        visualizer.add_pr_curves(self._classes, targets, pred_probs)\n",
    "        self._close_visualizer()\n",
    "    \n",
    "    def log_confusion_matrix(self):\n",
    "        targets, preds = predict_valid_data(\n",
    "            self.trained_model,\n",
    "            self.valid_loader,\n",
    "            self.device\n",
    "        )\n",
    "\n",
    "        visualizer = self._open_visualizer()\n",
    "        cm = confusion_matrix(targets, preds)\n",
    "        tag = f\"Confusion Matrix ({self.__model_name})\"\n",
    "        figure = create_confusion_matrix(cm, self.classes, self.__model_name)\n",
    "        visualizer.add_figure(tag=tag, figure=figure, close=True)\n",
    "        self._close_visualizer()\n",
    "\n",
    "    \"\"\"\n",
    "    Protected methods that may or must be overridden by derived classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    @property\n",
    "    def _visualizer_name(self) -> str:\n",
    "        return self.__model_name\n",
    "            \n",
    "    @abstractmethod\n",
    "    def _get_model(self) -> Tuple[nn.Module, str]:\n",
    "        pass\n",
    "    \n",
    "    \"\"\"\n",
    "    Private methods that should only be called by this base class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __load_model(self):\n",
    "        path = self.trained_model_path\n",
    "        if os.path.exists(path):\n",
    "            self.__model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLi5W6s06tZO"
   },
   "source": [
    "### <font style=\"color:blue\">Experiment #01: Training Pipeline Check and Data Visualization Experiments</font>\n",
    "\n",
    "This set of experiments will log images of each food to the visualizer and retrain the fc classification layer of the pretrained Resnet18 model using a subset of the data to validate the training pipeline. Normally, one would disabled data augmentation, but I am going to test that too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nCwE0ULBBU6"
   },
   "outputs": [],
   "source": [
    "class Exp01A(VisualExperiment):\n",
    "    def __init_(self):\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-HiT-bcR-U-G"
   },
   "outputs": [],
   "source": [
    "class Exp01B(ModelExperiment):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            use_data_subsets = True,\n",
    "            trainer_training_epochs = 100, \n",
    "            trainer_stop_acc_epochs = 10,\n",
    "            trainer_stop_acc_ema_alpha = 0.3,\n",
    "            trainer_stop_acc_threshold = 2.0\n",
    "        )\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return ResNet18(pretrained=True, tuning_level=0), \"ResNet18-PT_T-FTL_0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do_oOfMcBBU4"
   },
   "source": [
    "### <font style=\"color:blue\">Experiment #02 - Training the Classifier of Pretrained Models</font>\n",
    "\n",
    "This set of experiments retrains the classifer of the following pretrained models.\n",
    "<ul>\n",
    "    <li>ResNet-152</li>\n",
    "    <li>VGG-19 with batch normalization.</li>\n",
    "    <li>DenseNet-161</li>\n",
    "    <li>ResNeXt-101-32x8d</li>\n",
    "    <li>Wide ResNet-101-2</li>\n",
    "</ul>\n",
    "\n",
    "For efficiency, training will stop after 100 epochs or when the smoothed accuracy does not increase by 2% over 10 epochs. Accuracy is smoothed via an exponential moving average with an alpha of 0.3.\n",
    "\n",
    "<u>Results</u>: TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qszJetrV-U-H"
   },
   "outputs": [],
   "source": [
    "class Exp02(ModelExperiment):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            trainer_training_epochs = 100, \n",
    "            trainer_stop_acc_epochs = 10,\n",
    "            trainer_stop_acc_ema_alpha = 0.3,\n",
    "            trainer_stop_acc_threshold = 2.0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-6mEBX7DBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp02A(Exp02):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return ResNet152(pretrained=True, tuning_level=0), \"ResNet152-PT_T-FTL_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-0W5ppsBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp02B(Exp02):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return VGG19BN(pretrained=True, tuning_level=0), \"VGG19BN-PT_T-FTL_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcVAW4pBBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp02C(Exp02):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return DenseNet161(pretrained=True, tuning_level=0), \"DenseNet161-PT_T-FTL_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5HqO0_zBBU5"
   },
   "outputs": [],
   "source": [
    "class Exp02D(Exp02):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return ResNeXt101(pretrained=True, tuning_level=0), \"ResNeXt101-PT_T-FTL_0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xf1ZtmRyBBU5"
   },
   "outputs": [],
   "source": [
    "class Exp02E(Exp02):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return WideResNet101(pretrained=True, tuning_level=0), \"WideResNet101-PT_T-FTL_0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do_oOfMcBBU4"
   },
   "source": [
    "### <font style=\"color:blue\">Experiment #03 - Training the Classifier and Last Convolution Block of Pretrained Models</font>\n",
    "\n",
    "This set of experiments retrains the classifer and last convolution block of the following pretrained models.\n",
    "<ul>\n",
    "    <li>VGG-19 with batch normalization.</li>\n",
    "    <li>DenseNet-161</li>\n",
    "    <li>ResNeXt-101-32x8d</li>\n",
    "</ul>\n",
    "\n",
    "For efficiency, training will stop after 100 epochs or when the smoothed accuracy does not increase by 2% over 10 epochs. Accuracy is smoothed via an exponential moving average with an alpha of 0.3. The number of data loader workers is increased from 4 to 8.\n",
    "\n",
    "<u>Results</u>: TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qszJetrV-U-H"
   },
   "outputs": [],
   "source": [
    "class Exp03(ModelExperiment):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            data_loader_num_workers = 8,\n",
    "            trainer_training_epochs = 100, \n",
    "            trainer_stop_acc_epochs = 10,\n",
    "            trainer_stop_acc_ema_alpha = 0.3,\n",
    "            trainer_stop_acc_threshold = 2.0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-0W5ppsBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp03B(Exp03):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return VGG19BN(pretrained=True, tuning_level=1), \"VGG19BN-PT_T-FTL_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcVAW4pBBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp03C(Exp03):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return DenseNet161(pretrained=True, tuning_level=1), \"DenseNet161-PT_T-FTL_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5HqO0_zBBU5"
   },
   "outputs": [],
   "source": [
    "class Exp03D(Exp03):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return ResNeXt101(pretrained=True, tuning_level=1), \"ResNeXt101-PT_T-FTL_1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do_oOfMcBBU4"
   },
   "source": [
    "### <font style=\"color:blue\">Experiment #04 - Training the Classifier and Last 2 Convolution Blocks of Pretrained Models</font>\n",
    "\n",
    "This set of experiments retrains the classifer and last two convolution blocks of the following pretrained models.\n",
    "<ul>\n",
    "    <li>VGG-19 with batch normalization.</li>\n",
    "    <li>DenseNet-161</li>\n",
    "    <li>ResNeXt-101-32x8d</li>\n",
    "</ul>\n",
    "\n",
    "For efficiency, training will stop after 100 epochs or when the smoothed accuracy does not increase by 2% over 10 epochs. Accuracy is smoothed via an exponential moving average with an alpha of 0.3. The number of data loader workers is increased from 4 to 8.\n",
    "\n",
    "<u>Results</u>: TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qszJetrV-U-H"
   },
   "outputs": [],
   "source": [
    "class Exp04(ModelExperiment):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            data_loader_num_workers = 8,\n",
    "            trainer_training_epochs = 100, \n",
    "            trainer_stop_acc_epochs = 10,\n",
    "            trainer_stop_acc_ema_alpha = 0.3,\n",
    "            trainer_stop_acc_threshold = 2.0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-0W5ppsBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp04B(Exp04):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return VGG19BN(pretrained=True, tuning_level=2), \"VGG19BN-PT_T-FTL_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcVAW4pBBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp04C(Exp04):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return DenseNet161(pretrained=True, tuning_level=2), \"DenseNet161-PT_T-FTL_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5HqO0_zBBU5"
   },
   "outputs": [],
   "source": [
    "class Exp04D(Exp04):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return ResNeXt101(pretrained=True, tuning_level=2), \"ResNeXt101-PT_T-FTL_2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do_oOfMcBBU4"
   },
   "source": [
    "### <font style=\"color:blue\">Experiment #05 - Training the Classifier and Last 3 Convolution Blocks of Pretrained Models</font>\n",
    "\n",
    "This set of experiments retrains the classifer and last three convolution blocks of the following pretrained models.\n",
    "<ul>\n",
    "    <li>VGG-19 with batch normalization.</li>\n",
    "    <li>DenseNet-161</li>\n",
    "    <li>ResNeXt-101-32x8d</li>\n",
    "</ul>\n",
    "\n",
    "For efficiency, training will stop after 100 epochs or when the smoothed accuracy does not increase by 2% over 10 epochs. Accuracy is smoothed via an exponential moving average with an alpha of 0.3. The number of data loader workers is increased from 4 to 8.\n",
    "\n",
    "<u>Results</u>: TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qszJetrV-U-H"
   },
   "outputs": [],
   "source": [
    "class Exp05(ModelExperiment):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            data_loader_num_workers = 8,\n",
    "            trainer_training_epochs = 100, \n",
    "            trainer_stop_acc_epochs = 10,\n",
    "            trainer_stop_acc_ema_alpha = 0.3,\n",
    "            trainer_stop_acc_threshold = 2.0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-0W5ppsBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp05B(Exp05):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return VGG19BN(pretrained=True, tuning_level=3), \"VGG19BN-PT_T-FTL_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcVAW4pBBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp05C(Exp05):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return DenseNet161(pretrained=True, tuning_level=3), \"DenseNet161-PT_T-FTL_3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5HqO0_zBBU5"
   },
   "outputs": [],
   "source": [
    "class Exp05D(Exp05):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return ResNeXt101(pretrained=True, tuning_level=3), \"ResNeXt101-PT_T-FTL_3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do_oOfMcBBU4"
   },
   "source": [
    "### <font style=\"color:blue\">Experiment #06 - Training the Classifier and Last 4 Convolution Blocks of Pretrained Models</font>\n",
    "\n",
    "This set of experiments retrains the classifer and last four convolution blocks of the following pretrained models.\n",
    "<ul>\n",
    "    <li>VGG-19 with batch normalization.</li>\n",
    "    <li>DenseNet-161</li>\n",
    "    <li>ResNeXt-101-32x8d</li>\n",
    "</ul>\n",
    "\n",
    "For efficiency, training will stop after 100 epochs or when the smoothed accuracy does not increase by 2% over 10 epochs. Accuracy is smoothed via an exponential moving average with an alpha of 0.3. The number of data loader workers is increased from 4 to 8.\n",
    "\n",
    "<u>Results</u>: TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qszJetrV-U-H"
   },
   "outputs": [],
   "source": [
    "class Exp06(ModelExperiment):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            data_loader_num_workers = 8,\n",
    "            trainer_training_epochs = 100, \n",
    "            trainer_stop_acc_epochs = 10,\n",
    "            trainer_stop_acc_ema_alpha = 0.3,\n",
    "            trainer_stop_acc_threshold = 2.0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-0W5ppsBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp06B(Exp06):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return VGG19BN(pretrained=True, tuning_level=4), \"VGG19BN-PT_T-FTL_4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcVAW4pBBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp06C(Exp06):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return DenseNet161(pretrained=True, tuning_level=4), \"DenseNet161-PT_T-FTL_4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5HqO0_zBBU5"
   },
   "outputs": [],
   "source": [
    "class Exp06D(Exp06):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return ResNeXt101(pretrained=True, tuning_level=4), \"ResNeXt101-PT_T-FTL_4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do_oOfMcBBU4"
   },
   "source": [
    "### <font style=\"color:blue\">Experiment #07 - Training Pretrained Models</font>\n",
    "\n",
    "This set of experiments retrains the following pretrained models.\n",
    "<ul>\n",
    "    <li>VGG-19 with batch normalization.</li>\n",
    "    <li>DenseNet-161</li>\n",
    "    <li>ResNeXt-101-32x8d</li>\n",
    "</ul>\n",
    "\n",
    "For efficiency, training will stop after 100 epochs or when the smoothed accuracy does not increase by 2% over 10 epochs. Accuracy is smoothed via an exponential moving average with an alpha of 0.3. The number of data loader workers is increased from 4 to 8.\n",
    "\n",
    "<u>Results</u>: TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qszJetrV-U-H"
   },
   "outputs": [],
   "source": [
    "class Exp07(ModelExperiment):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            data_loader_num_workers = 8,\n",
    "            trainer_training_epochs = 100, \n",
    "            trainer_stop_acc_epochs = 10,\n",
    "            trainer_stop_acc_ema_alpha = 0.3,\n",
    "            trainer_stop_acc_threshold = 2.0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-0W5ppsBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp07B(Exp07):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return VGG19BN(pretrained=True, tuning_level=5), \"VGG19BN-PT_T-FTL_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcVAW4pBBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp07C(Exp07):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return DenseNet161(pretrained=True, tuning_level=5), \"DenseNet161-PT_T-FTL_5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5HqO0_zBBU5"
   },
   "outputs": [],
   "source": [
    "class Exp07D(Exp07):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return ResNeXt101(pretrained=True, tuning_level=5), \"ResNeXt101-PT_T-FTL_5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Do_oOfMcBBU4"
   },
   "source": [
    "### <font style=\"color:blue\">Experiment #08 - Training Untrained Models From Scratch</font>\n",
    "\n",
    "This set of experiments trains the following untrained models.\n",
    "<ul>\n",
    "    <li>VGG-19 with batch normalization.</li>\n",
    "    <li>DenseNet-161</li>\n",
    "    <li>ResNeXt-101-32x8d</li>\n",
    "</ul>\n",
    "\n",
    "For efficiency, training will stop after 100 epochs or when the smoothed accuracy does not increase by 2% over 10 epochs. Accuracy is smoothed via an exponential moving average with an alpha of 0.3. The number of data loader workers is increased from 4 to 8.\n",
    "\n",
    "<u>Results</u>: TBD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qszJetrV-U-H"
   },
   "outputs": [],
   "source": [
    "class Exp08(ModelExperiment):\n",
    "    def __init__(self):\n",
    "        super().__init__(\n",
    "            data_loader_num_workers = 8,\n",
    "            trainer_training_epochs = 100, \n",
    "            trainer_stop_acc_epochs = 10,\n",
    "            trainer_stop_acc_ema_alpha = 0.3,\n",
    "            trainer_stop_acc_threshold = 2.0\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-0W5ppsBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp08B(Exp08):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return VGG19BN(pretrained=False, tuning_level=0), \"VGG19BN-PT_F\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vcVAW4pBBBU4"
   },
   "outputs": [],
   "source": [
    "class Exp08C(Exp08):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return DenseNet161(pretrained=False, tuning_level=0), \"DenseNet161-PT_F\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I5HqO0_zBBU5"
   },
   "outputs": [],
   "source": [
    "class Exp08D(Exp08):\n",
    "    def _get_model(self) -> nn.Module:\n",
    "        return ResNeXt101(pretrained=False, tuning_level=0), \"ResNeXt101-PT_F\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kx9Gbfds3-53"
   },
   "source": [
    "### <font style=\"color:blue\">Main Function</font>\n",
    "\n",
    "A simple function that creates an experiment, trains its model, and logs the model's resulting PR curves and graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4PfNfZhivj8"
   },
   "outputs": [],
   "source": [
    "def vizdata(exp: VisualExperiment):\n",
    "    \"\"\"\n",
    "    This method visualizes a visualizer by logging sample images for each food type to the notebook visualizer.\n",
    "    (That's a lot of visualizers in one sentence!)\n",
    "    \"\"\"\n",
    "\n",
    "    exp.log_sample_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wNeoVzzzlDh8"
   },
   "outputs": [],
   "source": [
    "def conduct(exp: ModelExperiment):\n",
    "    \"\"\"\n",
    "    This method conducts an experiment by performing the following steps and returns its training metrics.\n",
    "    1. Trains the model.\n",
    "    2. Logs the model's precision-recall curve for each food class.\n",
    "    3. Logs the model's graph.\n",
    "    \n",
    "    The last two steps are performed on model state with the lowest average loss on the validaton set.\n",
    "    \"\"\"\n",
    "    \n",
    "    exp.log_graph()\n",
    "    metrics = exp.train()\n",
    "    exp.log_pr_curves()\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_group_0():\n",
    "    \"\"\"\n",
    "    Visualize the 13 food types of the KenyanFood13 datasset. Images are\n",
    "    resized to 256 x 256 pixels preserving their aspect ratios and then\n",
    "    center-cropped to 224 x 224 pixels. Check the training pipeline with\n",
    "    a simple model on a subset of the data.\n",
    "    \"\"\"\n",
    "    vizdata(Exp01A())\n",
    "    conduct(Exp01B())\n",
    "\n",
    "    \"\"\"\n",
    "    Retrain the classifer layer of the following pretrained models.\n",
    "        - ResNet-152\n",
    "        - VGG-19 with batch normalization.\n",
    "        - DenseNet-161\n",
    "        - ResNeXt-101-32x8d\n",
    "        - Wide ResNet-101-2\n",
    "    \"\"\"\n",
    "    conduct(Exp02A())\n",
    "    conduct(Exp02B())\n",
    "    conduct(Exp02C())\n",
    "    conduct(Exp02D())\n",
    "    conduct(Exp02E())\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Retrain the classifer and last convolution block of the following\n",
    "    pretrained models.\n",
    "        - VGG-19 with batch normalization.\n",
    "        - DenseNet-161\n",
    "        - ResNeXt-101-32x8d\n",
    "    \"\"\"\n",
    "    conduct(Exp03B())\n",
    "    conduct(Exp03C())\n",
    "    conduct(Exp03D())\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrain the classifer and last two convolution blocks of the following\n",
    "    pretrained models.\n",
    "        - VGG-19 with batch normalization.\n",
    "        - DenseNet-161\n",
    "        - ResNeXt-101-32x8d\n",
    "    \"\"\"\n",
    "    conduct(Exp04B())\n",
    "    conduct(Exp04C())\n",
    "    conduct(Exp04D())\n",
    "\n",
    "    \"\"\"\n",
    "    Retrain the classifer and last three convolution blocks of the following\n",
    "    pretrained models.\n",
    "        - VGG-19 with batch normalization.\n",
    "        - DenseNet-161\n",
    "        - ResNeXt-101-32x8d\n",
    "    \"\"\"\n",
    "    conduct(Exp05B())\n",
    "    conduct(Exp05C())\n",
    "    conduct(Exp05D())\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrain the classifer and last four convolution blocks of the following\n",
    "    pretrained models.\n",
    "        - VGG-19 with batch normalization.\n",
    "        - DenseNet-161\n",
    "        - ResNeXt-101-32x8d\n",
    "    \"\"\"\n",
    "    conduct(Exp06B())\n",
    "    conduct(Exp06C())\n",
    "    conduct(Exp06D())\n",
    "    \n",
    "    \"\"\"\n",
    "    Retrain the following pretrained models.\n",
    "        - VGG-19 with batch normalization.\n",
    "        - DenseNet-161\n",
    "        - ResNeXt-101-32x8d\n",
    "    \"\"\"\n",
    "    conduct(Exp07B())\n",
    "    conduct(Exp07C())\n",
    "    conduct(Exp07D())\n",
    "\n",
    "    \"\"\"\n",
    "    Train the following untrained models from scratch.\n",
    "        - VGG-19 with batch normalization.\n",
    "        - DenseNet-161\n",
    "        - ResNeXt-101-32x8d\n",
    "    \"\"\"\n",
    "    conduct(Exp08B())\n",
    "    conduct(Exp08C())\n",
    "    conduct(Exp08D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_group_1():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I9Q6_bS9lDh8"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    for group in [0]:\n",
    "        \n",
    "        if group == 0:\n",
    "            experiment_group_0()\n",
    "        elif group == 1:\n",
    "            experiment_group_1()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167,
     "referenced_widgets": [
      "3fd2b77dfa544f85837435ca5961ba8f",
      "96accc2fe8944764afa8c16633660ac7",
      "974c6aa67ffc42698fdb80f439dc4569",
      "ecd844ae701c4a31a9dd1f5cafde9078",
      "806a3f07103f4edc90294dc92b8aa455",
      "d24d1c8a70294e0690041ffb9d45453d",
      "bc96aba5b5da4c0ebac3137284bba1c1",
      "ad93bc6d66074fe8b119243baa0f4cf8",
      "823bc44be56c4a9993125d310e637705",
      "f1b83c7eddc44d2fb54726efc1848ce8",
      "f3dfe5dd75b24bada66d8ac1fc792fe4",
      "49fc9f376afb496e855d300a106e50e4",
      "bd9aafdad8654a1f931330bf91cdebd3",
      "de5dc6c1cc494e929f5d2d95813a17cc",
      "ac7ee576d9704909b64b208915e03a8a",
      "718df99acdca4a738abb6d301a5a0449",
      "889c5df7ebe543eb95e266bc51af7e21",
      "44af0c82674c4ae58d56c5ee7806e9fd",
      "542db1f2ce2f402c85a437ac303ac2fb",
      "a4ff39f28ca046a894a31d953fb9014a",
      "c4fdea457140450abff31fd1063400cc",
      "69147e87b38549a58fd337d31051742c",
      "c032ee196ffe4992a0eb175bb26d3358",
      "8edc6f437a3047f593fc706e4d9587c3"
     ]
    },
    "id": "G4Fe0mLZ3-53",
    "outputId": "50773fbe-c4b3-4e43-f0e4-7b513f8c5c6d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nFt15GPK3-53"
   },
   "source": [
    "## <font style=\"color:green\">8. TensorBoard Dev Scalars Log Link [5 Points]</font>\n",
    "\n",
    "Share your tensorboard scalars logs link in this section. You can also share (not mandatory) your GitHub link if you have pushed this project in GitHub. \n",
    "\n",
    "For example, [Find Project2 logs here](https://tensorboard.dev/experiment/kMJ4YU0wSNG0IkjrluQ5Dg/#scalars)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWFa-7uo3-53"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hh36KFmK3-53"
   },
   "source": [
    "## <font style=\"color:green\">9. Kaggle Profile Link [50 Points]</font>\n",
    "\n",
    "Share your Kaggle profile link here with us so that we can give points for the competition score. \n",
    "\n",
    "You should have a minimum accuracy of `75%` on the test data to get all points. If accuracy is less than `70%`, you will not get any points for the section. \n",
    "\n",
    "**You must have to submit `submission.csv` (prediction for images in `test.csv`) in `Submit Predictions` tab in Kaggle to get any evaluation in this section.**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Project2_Kaggle_Competition_Classification-4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3fd2b77dfa544f85837435ca5961ba8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_974c6aa67ffc42698fdb80f439dc4569",
       "IPY_MODEL_ecd844ae701c4a31a9dd1f5cafde9078"
      ],
      "layout": "IPY_MODEL_96accc2fe8944764afa8c16633660ac7"
     }
    },
    "44af0c82674c4ae58d56c5ee7806e9fd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "49fc9f376afb496e855d300a106e50e4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_718df99acdca4a738abb6d301a5a0449",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_ac7ee576d9704909b64b208915e03a8a",
      "value": " 0/100 [00:00&lt;?, ?it/s]"
     }
    },
    "542db1f2ce2f402c85a437ac303ac2fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "[0/100][Train][115] Loss_avg: 2.1766, Loss: 2.2303, LR: 0.001:  71%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69147e87b38549a58fd337d31051742c",
      "max": 164,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c4fdea457140450abff31fd1063400cc",
      "value": 116
     }
    },
    "69147e87b38549a58fd337d31051742c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "718df99acdca4a738abb6d301a5a0449": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "806a3f07103f4edc90294dc92b8aa455": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "823bc44be56c4a9993125d310e637705": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f3dfe5dd75b24bada66d8ac1fc792fe4",
       "IPY_MODEL_49fc9f376afb496e855d300a106e50e4"
      ],
      "layout": "IPY_MODEL_f1b83c7eddc44d2fb54726efc1848ce8"
     }
    },
    "889c5df7ebe543eb95e266bc51af7e21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_542db1f2ce2f402c85a437ac303ac2fb",
       "IPY_MODEL_a4ff39f28ca046a894a31d953fb9014a"
      ],
      "layout": "IPY_MODEL_44af0c82674c4ae58d56c5ee7806e9fd"
     }
    },
    "8edc6f437a3047f593fc706e4d9587c3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96accc2fe8944764afa8c16633660ac7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "974c6aa67ffc42698fdb80f439dc4569": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d24d1c8a70294e0690041ffb9d45453d",
      "max": 100441675,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_806a3f07103f4edc90294dc92b8aa455",
      "value": 100441675
     }
    },
    "a4ff39f28ca046a894a31d953fb9014a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8edc6f437a3047f593fc706e4d9587c3",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_c032ee196ffe4992a0eb175bb26d3358",
      "value": " 116/164 [07:15&lt;01:39,  2.07s/it]"
     }
    },
    "ac7ee576d9704909b64b208915e03a8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ad93bc6d66074fe8b119243baa0f4cf8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bc96aba5b5da4c0ebac3137284bba1c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bd9aafdad8654a1f931330bf91cdebd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c032ee196ffe4992a0eb175bb26d3358": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c4fdea457140450abff31fd1063400cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d24d1c8a70294e0690041ffb9d45453d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de5dc6c1cc494e929f5d2d95813a17cc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": "2",
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ecd844ae701c4a31a9dd1f5cafde9078": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad93bc6d66074fe8b119243baa0f4cf8",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_bc96aba5b5da4c0ebac3137284bba1c1",
      "value": " 95.8M/95.8M [00:12&lt;00:00, 7.82MB/s]"
     }
    },
    "f1b83c7eddc44d2fb54726efc1848ce8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": "inline-flex",
      "flex": null,
      "flex_flow": "row wrap",
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "100%"
     }
    },
    "f3dfe5dd75b24bada66d8ac1fc792fe4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_de5dc6c1cc494e929f5d2d95813a17cc",
      "max": 100,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bd9aafdad8654a1f931330bf91cdebd3",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}